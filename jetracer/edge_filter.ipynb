{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneLayerModel - 3x3 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.1798, -0.1643, -0.3176],\n",
      "          [-0.1097, -0.0890, -0.1372],\n",
      "          [ 0.2165,  0.0053, -0.0446]]]]) \n",
      "\n",
      "### Epoch_1 ###\n",
      "\n",
      "The output is tensor([[[-0.7472]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 14.04169750213623\n",
      "\n",
      "tensor([[[[ 0.1798, -0.0893, -0.2426],\n",
      "          [-0.1097, -0.0140, -0.0622],\n",
      "          [ 0.2165,  0.0803,  0.0304]]]]) \n",
      "\n",
      "The output is tensor([[[0.2637]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 10.651474952697754\n",
      "\n",
      "tensor([[[[ 0.1146, -0.1546, -0.2426],\n",
      "          [-0.1749, -0.0793, -0.0622],\n",
      "          [ 0.1513,  0.0150,  0.0304]]]]) \n",
      "\n",
      "The output is tensor([[[-0.4025]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.1619895100593567\n",
      "\n",
      "tensor([[[[ 0.1226, -0.1466, -0.2346],\n",
      "          [-0.1669, -0.0712, -0.0542],\n",
      "          [ 0.1593,  0.0231,  0.0384]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[ 0.1226, -0.1466, -0.2346],\n",
      "          [-0.1669, -0.0712, -0.0542],\n",
      "          [ 0.1593,  0.0231,  0.0384]]]]) \n",
      "\n",
      "### Epoch_2 ###\n",
      "\n",
      "The output is tensor([[[-0.4451]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 11.86857795715332\n",
      "\n",
      "tensor([[[[ 0.1226, -0.0777, -0.1657],\n",
      "          [-0.1669, -0.0023,  0.0147],\n",
      "          [ 0.1593,  0.0920,  0.1073]]]]) \n",
      "\n",
      "The output is tensor([[[0.1270]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 9.778271675109863\n",
      "\n",
      "tensor([[[[ 0.0601, -0.1402, -0.1657],\n",
      "          [-0.2294, -0.0649,  0.0147],\n",
      "          [ 0.0968,  0.0294,  0.1073]]]]) \n",
      "\n",
      "The output is tensor([[[-0.2919]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.08518581837415695\n",
      "\n",
      "tensor([[[[ 0.0659, -0.1344, -0.1599],\n",
      "          [-0.2236, -0.0590,  0.0206],\n",
      "          [ 0.1026,  0.0353,  0.1131]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[ 0.0659, -0.1344, -0.1599],\n",
      "          [-0.2236, -0.0590,  0.0206],\n",
      "          [ 0.1026,  0.0353,  0.1131]]]]) \n",
      "\n",
      "### Epoch_3 ###\n",
      "\n",
      "The output is tensor([[[-0.1843]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 10.139564514160156\n",
      "\n",
      "tensor([[[[ 0.0659, -0.0707, -0.0962],\n",
      "          [-0.2236,  0.0046,  0.0843],\n",
      "          [ 0.1026,  0.0990,  0.1768]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0221]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 8.867650032043457\n",
      "\n",
      "tensor([[[[ 0.0064, -0.1302, -0.0962],\n",
      "          [-0.2831, -0.0549,  0.0843],\n",
      "          [ 0.0431,  0.0394,  0.1768]]]]) \n",
      "\n",
      "The output is tensor([[[-0.2146]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.04603651911020279\n",
      "\n",
      "tensor([[[[ 0.0106, -0.1259, -0.0919],\n",
      "          [-0.2789, -0.0506,  0.0886],\n",
      "          [ 0.0474,  0.0437,  0.1811]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[ 0.0106, -0.1259, -0.0919],\n",
      "          [-0.2789, -0.0506,  0.0886],\n",
      "          [ 0.0474,  0.0437,  0.1811]]]]) \n",
      "\n",
      "### Epoch_4 ###\n",
      "\n",
      "The output is tensor([[[0.0449]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 8.732499122619629\n",
      "\n",
      "tensor([[[[ 0.0106, -0.0668, -0.0328],\n",
      "          [-0.2789,  0.0085,  0.1477],\n",
      "          [ 0.0474,  0.1028,  0.2402]]]]) \n",
      "\n",
      "The output is tensor([[[-0.1764]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 7.9725422859191895\n",
      "\n",
      "tensor([[[[-0.0458, -0.1233, -0.0328],\n",
      "          [-0.3353, -0.0480,  0.1477],\n",
      "          [-0.0091,  0.0463,  0.2402]]]]) \n",
      "\n",
      "The output is tensor([[[-0.1602]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.025650830939412117\n",
      "\n",
      "tensor([[[[-0.0426, -0.1201, -0.0296],\n",
      "          [-0.3321, -0.0448,  0.1509],\n",
      "          [-0.0059,  0.0495,  0.2434]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.0426, -0.1201, -0.0296],\n",
      "          [-0.3321, -0.0448,  0.1509],\n",
      "          [-0.0059,  0.0495,  0.2434]]]]) \n",
      "\n",
      "### Epoch_5 ###\n",
      "\n",
      "The output is tensor([[[0.2493]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 7.566161632537842\n",
      "\n",
      "tensor([[[[-0.0426, -0.0651,  0.0254],\n",
      "          [-0.3321,  0.0102,  0.2059],\n",
      "          [-0.0059,  0.1045,  0.2984]]]]) \n",
      "\n",
      "The output is tensor([[[-0.3310]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 7.123559474945068\n",
      "\n",
      "tensor([[[[-0.0960, -0.1185,  0.0254],\n",
      "          [-0.3855, -0.0432,  0.2059],\n",
      "          [-0.0593,  0.0512,  0.2984]]]]) \n",
      "\n",
      "The output is tensor([[[-0.1215]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.014769619330763817\n",
      "\n",
      "tensor([[[[-0.0936, -0.1160,  0.0279],\n",
      "          [-0.3831, -0.0407,  0.2083],\n",
      "          [-0.0569,  0.0536,  0.3009]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.0936, -0.1160,  0.0279],\n",
      "          [-0.3831, -0.0407,  0.2083],\n",
      "          [-0.0569,  0.0536,  0.3009]]]]) \n",
      "\n",
      "### Epoch_6 ###\n",
      "\n",
      "The output is tensor([[[0.4339]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 6.585086345672607\n",
      "\n",
      "tensor([[[[-0.0936, -0.0647,  0.0792],\n",
      "          [-0.3831,  0.0106,  0.2596],\n",
      "          [-0.0569,  0.1049,  0.3522]]]]) \n",
      "\n",
      "The output is tensor([[[-0.4827]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 6.336658477783203\n",
      "\n",
      "tensor([[[[-0.1439, -0.1151,  0.0792],\n",
      "          [-0.4334, -0.0397,  0.2596],\n",
      "          [-0.1072,  0.0546,  0.3522]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0938]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.008796630427241325\n",
      "\n",
      "tensor([[[[-0.1420, -0.1132,  0.0811],\n",
      "          [-0.4315, -0.0379,  0.2615],\n",
      "          [-0.1053,  0.0564,  0.3541]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.1420, -0.1132,  0.0811],\n",
      "          [-0.4315, -0.0379,  0.2615],\n",
      "          [-0.1053,  0.0564,  0.3541]]]]) \n",
      "\n",
      "### Epoch_7 ###\n",
      "\n",
      "The output is tensor([[[0.6020]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 5.750339984893799\n",
      "\n",
      "tensor([[[[-0.1420, -0.0652,  0.1290],\n",
      "          [-0.4315,  0.0101,  0.3095],\n",
      "          [-0.1053,  0.1044,  0.4020]]]]) \n",
      "\n",
      "The output is tensor([[[-0.6297]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 5.618480682373047\n",
      "\n",
      "tensor([[[[-0.1895, -0.1126,  0.1290],\n",
      "          [-0.4789, -0.0373,  0.3095],\n",
      "          [-0.1527,  0.0570,  0.4020]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0736]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.005415445659309626\n",
      "\n",
      "tensor([[[[-0.1880, -0.1112,  0.1305],\n",
      "          [-0.4775, -0.0358,  0.3109],\n",
      "          [-0.1513,  0.0585,  0.4035]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.1880, -0.1112,  0.1305],\n",
      "          [-0.4775, -0.0358,  0.3109],\n",
      "          [-0.1513,  0.0585,  0.4035]]]]) \n",
      "\n",
      "### Epoch_8 ###\n",
      "\n",
      "The output is tensor([[[0.7564]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 5.033819675445557\n",
      "\n",
      "tensor([[[[-0.1880, -0.0663,  0.1754],\n",
      "          [-0.4775,  0.0090,  0.3558],\n",
      "          [-0.1513,  0.1033,  0.4484]]]]) \n",
      "\n",
      "The output is tensor([[[-0.7707]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 4.969961643218994\n",
      "\n",
      "tensor([[[[-0.2326, -0.1109,  0.1754],\n",
      "          [-0.5221, -0.0356,  0.3558],\n",
      "          [-0.1959,  0.0587,  0.4484]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0586]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0034375281538814306\n",
      "\n",
      "tensor([[[[-0.2314, -0.1097,  0.1765],\n",
      "          [-0.5209, -0.0344,  0.3570],\n",
      "          [-0.1947,  0.0599,  0.4496]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.2314, -0.1097,  0.1765],\n",
      "          [-0.5209, -0.0344,  0.3570],\n",
      "          [-0.1947,  0.0599,  0.4496]]]]) \n",
      "\n",
      "### Epoch_9 ###\n",
      "\n",
      "The output is tensor([[[0.8989]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 4.4146552085876465\n",
      "\n",
      "tensor([[[[-0.2314, -0.0677,  0.2186],\n",
      "          [-0.5209,  0.0076,  0.3990],\n",
      "          [-0.1947,  0.1019,  0.4916]]]]) \n",
      "\n",
      "The output is tensor([[[-0.9051]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 4.388700485229492\n",
      "\n",
      "tensor([[[[-0.2733, -0.1096,  0.2186],\n",
      "          [-0.5628, -0.0343,  0.3990],\n",
      "          [-0.2366,  0.0600,  0.4916]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0473]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0022405795753002167\n",
      "\n",
      "tensor([[[[-0.2723, -0.1086,  0.2195],\n",
      "          [-0.5618, -0.0333,  0.3999],\n",
      "          [-0.2356,  0.0610,  0.4925]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.2723, -0.1086,  0.2195],\n",
      "          [-0.5618, -0.0333,  0.3999],\n",
      "          [-0.2356,  0.0610,  0.4925]]]]) \n",
      "\n",
      "### Epoch_10 ###\n",
      "\n",
      "The output is tensor([[[1.0310]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 3.8769233226776123\n",
      "\n",
      "tensor([[[[-0.2723, -0.0693,  0.2589],\n",
      "          [-0.5618,  0.0061,  0.4393],\n",
      "          [-0.2356,  0.1004,  0.5319]]]]) \n",
      "\n",
      "The output is tensor([[[-1.0326]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 3.870471239089966\n",
      "\n",
      "tensor([[[[-0.3117, -0.1086,  0.2589],\n",
      "          [-0.6012, -0.0333,  0.4393],\n",
      "          [-0.2750,  0.0610,  0.5319]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0386]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0014913337072357535\n",
      "\n",
      "tensor([[[[-0.3109, -0.1078,  0.2597],\n",
      "          [-0.6004, -0.0325,  0.4401],\n",
      "          [-0.2742,  0.0618,  0.5327]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.3109, -0.1078,  0.2597],\n",
      "          [-0.6004, -0.0325,  0.4401],\n",
      "          [-0.2742,  0.0618,  0.5327]]]]) \n",
      "\n",
      "### Epoch_11 ###\n",
      "\n",
      "The output is tensor([[[1.1539]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 3.4081532955169678\n",
      "\n",
      "tensor([[[[-0.3109, -0.0709,  0.2966],\n",
      "          [-0.6004,  0.0044,  0.4770],\n",
      "          [-0.2742,  0.0987,  0.5696]]]]) \n",
      "\n",
      "The output is tensor([[[-1.1533]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 3.410191535949707\n",
      "\n",
      "tensor([[[[-0.3479, -0.1078,  0.2966],\n",
      "          [-0.6373, -0.0325,  0.4770],\n",
      "          [-0.3111,  0.0618,  0.5696]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0317]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0010069666896015406\n",
      "\n",
      "tensor([[[[-0.3472, -0.1072,  0.2972],\n",
      "          [-0.6367, -0.0319,  0.4777],\n",
      "          [-0.3105,  0.0624,  0.5702]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.3472, -0.1072,  0.2972],\n",
      "          [-0.6367, -0.0319,  0.4777],\n",
      "          [-0.3105,  0.0624,  0.5702]]]]) \n",
      "\n",
      "### Epoch_12 ###\n",
      "\n",
      "The output is tensor([[[1.2684]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 2.998357057571411\n",
      "\n",
      "tensor([[[[-0.3472, -0.0726,  0.3319],\n",
      "          [-0.6367,  0.0027,  0.5123],\n",
      "          [-0.3105,  0.0970,  0.6049]]]]) \n",
      "\n",
      "The output is tensor([[[-1.2672]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 3.002500534057617\n",
      "\n",
      "tensor([[[[-0.3819, -0.1072,  0.3319],\n",
      "          [-0.6714, -0.0319,  0.5123],\n",
      "          [-0.3452,  0.0624,  0.6049]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0262]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0006845764582976699\n",
      "\n",
      "tensor([[[[-0.3814, -0.1067,  0.3324],\n",
      "          [-0.6708, -0.0314,  0.5128],\n",
      "          [-0.3446,  0.0629,  0.6054]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.3814, -0.1067,  0.3324],\n",
      "          [-0.6708, -0.0314,  0.5128],\n",
      "          [-0.3446,  0.0629,  0.6054]]]]) \n",
      "\n",
      "### Epoch_13 ###\n",
      "\n",
      "The output is tensor([[[1.3754]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 2.6393706798553467\n",
      "\n",
      "tensor([[[[-0.3814, -0.0742,  0.3649],\n",
      "          [-0.6708,  0.0011,  0.5453],\n",
      "          [-0.3446,  0.0954,  0.6379]]]]) \n",
      "\n",
      "The output is tensor([[[-1.3745]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 2.642108201980591\n",
      "\n",
      "tensor([[[[-0.4139, -0.1067,  0.3649],\n",
      "          [-0.7034, -0.0314,  0.5453],\n",
      "          [-0.3772,  0.0629,  0.6379]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0216]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00046465685591101646\n",
      "\n",
      "tensor([[[[-0.4134, -0.1063,  0.3653],\n",
      "          [-0.7029, -0.0310,  0.5457],\n",
      "          [-0.3767,  0.0633,  0.6383]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.4134, -0.1063,  0.3653],\n",
      "          [-0.7029, -0.0310,  0.5457],\n",
      "          [-0.3767,  0.0633,  0.6383]]]]) \n",
      "\n",
      "### Epoch_14 ###\n",
      "\n",
      "The output is tensor([[[1.4754]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 2.3244080543518066\n",
      "\n",
      "tensor([[[[-4.1343e-01, -7.5806e-02,  3.9579e-01],\n",
      "          [-7.0292e-01, -4.7873e-04,  5.7622e-01],\n",
      "          [-3.7672e-01,  9.3824e-02,  6.6880e-01]]]]) \n",
      "\n",
      "The output is tensor([[[-1.4755]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 2.323991537094116\n",
      "\n",
      "tensor([[[[-0.4439, -0.1063,  0.3958],\n",
      "          [-0.7334, -0.0310,  0.5762],\n",
      "          [-0.4072,  0.0633,  0.6688]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0177]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0003118553140666336\n",
      "\n",
      "tensor([[[[-0.4436, -0.1059,  0.3961],\n",
      "          [-0.7331, -0.0306,  0.5766],\n",
      "          [-0.4069,  0.0637,  0.6692]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.4436, -0.1059,  0.3961],\n",
      "          [-0.7331, -0.0306,  0.5766],\n",
      "          [-0.4069,  0.0637,  0.6692]]]]) \n",
      "\n",
      "### Epoch_15 ###\n",
      "\n",
      "The output is tensor([[[1.5690]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 2.0477540493011475\n",
      "\n",
      "tensor([[[[-0.4436, -0.0773,  0.4248],\n",
      "          [-0.7331, -0.0020,  0.6052],\n",
      "          [-0.4069,  0.0923,  0.6978]]]]) \n",
      "\n",
      "The output is tensor([[[-1.5705]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 2.043492317199707\n",
      "\n",
      "tensor([[[[-0.4722, -0.1059,  0.4248],\n",
      "          [-0.7616, -0.0306,  0.6052],\n",
      "          [-0.4354,  0.0637,  0.6978]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0143]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002045459405053407\n",
      "\n",
      "tensor([[[[-0.4719, -0.1056,  0.4251],\n",
      "          [-0.7614, -0.0303,  0.6055],\n",
      "          [-0.4352,  0.0640,  0.6981]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.4719, -0.1056,  0.4251],\n",
      "          [-0.7614, -0.0303,  0.6055],\n",
      "          [-0.4352,  0.0640,  0.6981]]]]) \n",
      "\n",
      "### Epoch_16 ###\n",
      "\n",
      "The output is tensor([[[1.6567]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.804540991783142\n",
      "\n",
      "tensor([[[[-0.4719, -0.0788,  0.4519],\n",
      "          [-0.7614, -0.0034,  0.6323],\n",
      "          [-0.4352,  0.0909,  0.7249]]]]) \n",
      "\n",
      "The output is tensor([[[-1.6597]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.7963579893112183\n",
      "\n",
      "tensor([[[[-0.4987, -0.1056,  0.4519],\n",
      "          [-0.7882, -0.0302,  0.6323],\n",
      "          [-0.4620,  0.0641,  0.7249]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0114]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00012908728967886418\n",
      "\n",
      "tensor([[[[-0.4984, -0.1053,  0.4521],\n",
      "          [-0.7879, -0.0300,  0.6326],\n",
      "          [-0.4617,  0.0643,  0.7252]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.4984, -0.1053,  0.4521],\n",
      "          [-0.7879, -0.0300,  0.6326],\n",
      "          [-0.4617,  0.0643,  0.7252]]]]) \n",
      "\n",
      "### Epoch_17 ###\n",
      "\n",
      "The output is tensor([[[1.7388]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.5905898809432983\n",
      "\n",
      "tensor([[[[-0.4984, -0.0801,  0.4774],\n",
      "          [-0.7879, -0.0048,  0.6578],\n",
      "          [-0.4617,  0.0895,  0.7504]]]]) \n",
      "\n",
      "The output is tensor([[[-1.7435]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.5787506103515625\n",
      "\n",
      "tensor([[[[-0.5236, -0.1052,  0.4774],\n",
      "          [-0.8131, -0.0299,  0.6578],\n",
      "          [-0.4869,  0.0644,  0.7504]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0088]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 7.660147093702108e-05\n",
      "\n",
      "tensor([[[[-0.5234, -0.1051,  0.4775],\n",
      "          [-0.8129, -0.0297,  0.6580],\n",
      "          [-0.4867,  0.0646,  0.7506]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.5234, -0.1051,  0.4775],\n",
      "          [-0.8129, -0.0297,  0.6580],\n",
      "          [-0.4867,  0.0646,  0.7506]]]]) \n",
      "\n",
      "### Epoch_18 ###\n",
      "\n",
      "The output is tensor([[[1.8158]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.4022877216339111\n",
      "\n",
      "tensor([[[[-0.5234, -0.0814,  0.5012],\n",
      "          [-0.8129, -0.0061,  0.6817],\n",
      "          [-0.4867,  0.0882,  0.7742]]]]) \n",
      "\n",
      "The output is tensor([[[-1.8222]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.3872289657592773\n",
      "\n",
      "tensor([[[[-0.5470, -0.1049,  0.5012],\n",
      "          [-0.8365, -0.0296,  0.6817],\n",
      "          [-0.5103,  0.0647,  0.7742]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0064]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 4.110876761842519e-05\n",
      "\n",
      "tensor([[[[-0.5468, -0.1048,  0.5014],\n",
      "          [-0.8363, -0.0295,  0.6818],\n",
      "          [-0.5101,  0.0648,  0.7744]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.5468, -0.1048,  0.5014],\n",
      "          [-0.8363, -0.0295,  0.6818],\n",
      "          [-0.5101,  0.0648,  0.7744]]]]) \n",
      "\n",
      "### Epoch_19 ###\n",
      "\n",
      "The output is tensor([[[1.8880]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.2364983558654785\n",
      "\n",
      "tensor([[[[-0.5468, -0.0826,  0.5236],\n",
      "          [-0.8363, -0.0072,  0.7040],\n",
      "          [-0.5101,  0.0871,  0.7966]]]]) \n",
      "\n",
      "The output is tensor([[[-1.8960]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.2187235355377197\n",
      "\n",
      "tensor([[[[-0.5689, -0.1047,  0.5236],\n",
      "          [-0.8584, -0.0293,  0.7040],\n",
      "          [-0.5322,  0.0650,  0.7966]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0043]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.8447975890012458e-05\n",
      "\n",
      "tensor([[[[-0.5688, -0.1046,  0.5237],\n",
      "          [-0.8583, -0.0292,  0.7041],\n",
      "          [-0.5321,  0.0651,  0.7967]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.5688, -0.1046,  0.5237],\n",
      "          [-0.8583, -0.0292,  0.7041],\n",
      "          [-0.5321,  0.0651,  0.7967]]]]) \n",
      "\n",
      "### Epoch_20 ###\n",
      "\n",
      "The output is tensor([[[1.9557]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.0904874801635742\n",
      "\n",
      "tensor([[[[-0.5688, -0.0837,  0.5446],\n",
      "          [-0.8583, -0.0084,  0.7250],\n",
      "          [-0.5321,  0.0859,  0.8176]]]]) \n",
      "\n",
      "The output is tensor([[[-1.9653]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.070509910583496\n",
      "\n",
      "tensor([[[[-0.5895, -0.1044,  0.5446],\n",
      "          [-0.8790, -0.0290,  0.7250],\n",
      "          [-0.5528,  0.0653,  0.8176]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0024]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 5.611815140582621e-06\n",
      "\n",
      "tensor([[[[-0.5895, -0.1043,  0.5446],\n",
      "          [-0.8790, -0.0290,  0.7250],\n",
      "          [-0.5528,  0.0653,  0.8176]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.5895, -0.1043,  0.5446],\n",
      "          [-0.8790, -0.0290,  0.7250],\n",
      "          [-0.5528,  0.0653,  0.8176]]]]) \n",
      "\n",
      "### Epoch_21 ###\n",
      "\n",
      "The output is tensor([[[2.0193]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.9618651270866394\n",
      "\n",
      "tensor([[[[-0.5895, -0.0847,  0.5642],\n",
      "          [-0.8790, -0.0094,  0.7447],\n",
      "          [-0.5528,  0.0849,  0.8372]]]]) \n",
      "\n",
      "The output is tensor([[[-2.0304]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.9401726126670837\n",
      "\n",
      "tensor([[[[-0.6089, -0.1041,  0.5642],\n",
      "          [-0.8984, -0.0288,  0.7447],\n",
      "          [-0.5722,  0.0655,  0.8372]]]]) \n",
      "\n",
      "The output is tensor([[[-0.0006]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 3.6947938042430906e-07\n",
      "\n",
      "tensor([[[[-0.6089, -0.1041,  0.5642],\n",
      "          [-0.8983, -0.0288,  0.7447],\n",
      "          [-0.5721,  0.0655,  0.8372]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.6089, -0.1041,  0.5642],\n",
      "          [-0.8983, -0.0288,  0.7447],\n",
      "          [-0.5721,  0.0655,  0.8372]]]]) \n",
      "\n",
      "### Epoch_22 ###\n",
      "\n",
      "The output is tensor([[[2.0788]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.8485396504402161\n",
      "\n",
      "tensor([[[[-0.6089, -0.0857,  0.5827],\n",
      "          [-0.8983, -0.0103,  0.7631],\n",
      "          [-0.5721,  0.0840,  0.8557]]]]) \n",
      "\n",
      "The output is tensor([[[-2.0914]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.8255770802497864\n",
      "\n",
      "tensor([[[[-0.6270, -0.1038,  0.5827],\n",
      "          [-0.9165, -0.0285,  0.7631],\n",
      "          [-0.5903,  0.0658,  0.8557]]]]) \n",
      "\n",
      "The output is tensor([[[0.0010]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.0152911045224755e-06\n",
      "\n",
      "tensor([[[[-0.6270, -0.1039,  0.5826],\n",
      "          [-0.9165, -0.0285,  0.7631],\n",
      "          [-0.5903,  0.0658,  0.8557]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.6270, -0.1039,  0.5826],\n",
      "          [-0.9165, -0.0285,  0.7631],\n",
      "          [-0.5903,  0.0658,  0.8557]]]]) \n",
      "\n",
      "### Epoch_23 ###\n",
      "\n",
      "The output is tensor([[[2.1347]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.7486754655838013\n",
      "\n",
      "tensor([[[[-0.6270, -0.0866,  0.5999],\n",
      "          [-0.9165, -0.0112,  0.7804],\n",
      "          [-0.5903,  0.0831,  0.8730]]]]) \n",
      "\n",
      "The output is tensor([[[-2.1486]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.7248375415802002\n",
      "\n",
      "tensor([[[[-0.6441, -0.1036,  0.5999],\n",
      "          [-0.9336, -0.0283,  0.7804],\n",
      "          [-0.6074,  0.0660,  0.8730]]]]) \n",
      "\n",
      "The output is tensor([[[0.0025]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 6.2130879996402655e-06\n",
      "\n",
      "tensor([[[[-0.6441, -0.1036,  0.5999],\n",
      "          [-0.9336, -0.0283,  0.7803],\n",
      "          [-0.6074,  0.0660,  0.8729]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.6441, -0.1036,  0.5999],\n",
      "          [-0.9336, -0.0283,  0.7803],\n",
      "          [-0.6074,  0.0660,  0.8729]]]]) \n",
      "\n",
      "### Epoch_24 ###\n",
      "\n",
      "The output is tensor([[[2.1872]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.6606611609458923\n",
      "\n",
      "tensor([[[[-0.6441, -0.0874,  0.6162],\n",
      "          [-0.9336, -0.0121,  0.7966],\n",
      "          [-0.6074,  0.0823,  0.8892]]]]) \n",
      "\n",
      "The output is tensor([[[-2.2023]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.6362913250923157\n",
      "\n",
      "tensor([[[[-0.6601, -0.1033,  0.6162],\n",
      "          [-0.9496, -0.0280,  0.7966],\n",
      "          [-0.6234,  0.0663,  0.8892]]]]) \n",
      "\n",
      "The output is tensor([[[0.0039]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.4898194422130473e-05\n",
      "\n",
      "tensor([[[[-0.6602, -0.1034,  0.6161],\n",
      "          [-0.9496, -0.0281,  0.7965],\n",
      "          [-0.6234,  0.0662,  0.8891]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.6602, -0.1034,  0.6161],\n",
      "          [-0.9496, -0.0281,  0.7965],\n",
      "          [-0.6234,  0.0662,  0.8891]]]]) \n",
      "\n",
      "### Epoch_25 ###\n",
      "\n",
      "The output is tensor([[[2.2364]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.5830807685852051\n",
      "\n",
      "tensor([[[[-0.6602, -0.0881,  0.6313],\n",
      "          [-0.9496, -0.0128,  0.8118],\n",
      "          [-0.6234,  0.0815,  0.9044]]]]) \n",
      "\n",
      "The output is tensor([[[-2.2527]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.5584717392921448\n",
      "\n",
      "tensor([[[[-0.6751, -0.1031,  0.6313],\n",
      "          [-0.9646, -0.0278,  0.8118],\n",
      "          [-0.6384,  0.0665,  0.9044]]]]) \n",
      "\n",
      "The output is tensor([[[0.0051]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 2.6211137083009817e-05\n",
      "\n",
      "tensor([[[[-0.6752, -0.1032,  0.6312],\n",
      "          [-0.9647, -0.0279,  0.8117],\n",
      "          [-0.6385,  0.0664,  0.9043]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.6752, -0.1032,  0.6312],\n",
      "          [-0.9647, -0.0279,  0.8117],\n",
      "          [-0.6385,  0.0664,  0.9043]]]]) \n",
      "\n",
      "### Epoch_26 ###\n",
      "\n",
      "The output is tensor([[[2.2826]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.5146892070770264\n",
      "\n",
      "tensor([[[[-0.6752, -0.0888,  0.6456],\n",
      "          [-0.9647, -0.0135,  0.8260],\n",
      "          [-0.6385,  0.0808,  0.9186]]]]) \n",
      "\n",
      "The output is tensor([[[-2.2999]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.4900885224342346\n",
      "\n",
      "tensor([[[[-0.6892, -0.1028,  0.6456],\n",
      "          [-0.9787, -0.0275,  0.8260],\n",
      "          [-0.6525,  0.0668,  0.9186]]]]) \n",
      "\n",
      "The output is tensor([[[0.0063]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 3.944594936911017e-05\n",
      "\n",
      "tensor([[[[-0.6893, -0.1030,  0.6455],\n",
      "          [-0.9788, -0.0276,  0.8259],\n",
      "          [-0.6526,  0.0667,  0.9185]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.6893, -0.1030,  0.6455],\n",
      "          [-0.9788, -0.0276,  0.8259],\n",
      "          [-0.6526,  0.0667,  0.9185]]]]) \n",
      "\n",
      "### Epoch_27 ###\n",
      "\n",
      "The output is tensor([[[2.3259]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.4543914198875427\n",
      "\n",
      "tensor([[[[-0.6893, -0.0895,  0.6590],\n",
      "          [-0.9788, -0.0142,  0.8394],\n",
      "          [-0.6526,  0.0801,  0.9320]]]]) \n",
      "\n",
      "The output is tensor([[[-2.3443]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.430004358291626\n",
      "\n",
      "tensor([[[[-0.7024, -0.1026,  0.6590],\n",
      "          [-0.9919, -0.0273,  0.8394],\n",
      "          [-0.6657,  0.0670,  0.9320]]]]) \n",
      "\n",
      "The output is tensor([[[0.0074]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 5.403780232882127e-05\n",
      "\n",
      "tensor([[[[-0.7026, -0.1027,  0.6588],\n",
      "          [-0.9921, -0.0274,  0.8392],\n",
      "          [-0.6659,  0.0669,  0.9318]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.7026, -0.1027,  0.6588],\n",
      "          [-0.9921, -0.0274,  0.8392],\n",
      "          [-0.6659,  0.0669,  0.9318]]]]) \n",
      "\n",
      "### Epoch_28 ###\n",
      "\n",
      "The output is tensor([[[2.3666]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.40122389793395996\n",
      "\n",
      "tensor([[[[-0.7026, -0.0901,  0.6715],\n",
      "          [-0.9921, -0.0147,  0.8519],\n",
      "          [-0.6659,  0.0796,  0.9445]]]]) \n",
      "\n",
      "The output is tensor([[[-2.3858]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.37721776962280273\n",
      "\n",
      "tensor([[[[-0.7149, -0.1024,  0.6715],\n",
      "          [-1.0044, -0.0270,  0.8519],\n",
      "          [-0.6782,  0.0673,  0.9445]]]]) \n",
      "\n",
      "The output is tensor([[[0.0083]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 6.94999544066377e-05\n",
      "\n",
      "tensor([[[[-0.7150, -0.1025,  0.6713],\n",
      "          [-1.0045, -0.0272,  0.8517],\n",
      "          [-0.6783,  0.0671,  0.9443]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.7150, -0.1025,  0.6713],\n",
      "          [-1.0045, -0.0272,  0.8517],\n",
      "          [-0.6783,  0.0671,  0.9443]]]]) \n",
      "\n",
      "### Epoch_29 ###\n",
      "\n",
      "The output is tensor([[[2.4047]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.35433775186538696\n",
      "\n",
      "tensor([[[[-0.7150, -0.0906,  0.6832],\n",
      "          [-1.0045, -0.0153,  0.8636],\n",
      "          [-0.6783,  0.0790,  0.9562]]]]) \n",
      "\n",
      "The output is tensor([[[-2.4248]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.3308485448360443\n",
      "\n",
      "tensor([[[[-0.7265, -0.1021,  0.6832],\n",
      "          [-1.0160, -0.0268,  0.8636],\n",
      "          [-0.6898,  0.0675,  0.9562]]]]) \n",
      "\n",
      "The output is tensor([[[0.0092]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 8.546080789528787e-05\n",
      "\n",
      "tensor([[[[-0.7267, -0.1023,  0.6830],\n",
      "          [-1.0162, -0.0270,  0.8635],\n",
      "          [-0.6900,  0.0673,  0.9560]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.7267, -0.1023,  0.6830],\n",
      "          [-1.0162, -0.0270,  0.8635],\n",
      "          [-0.6900,  0.0673,  0.9560]]]]) \n",
      "\n",
      "### Epoch_30 ###\n",
      "\n",
      "The output is tensor([[[2.4405]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.3129868805408478\n",
      "\n",
      "tensor([[[[-0.7267, -0.0911,  0.6942],\n",
      "          [-1.0162, -0.0158,  0.8746],\n",
      "          [-0.6900,  0.0785,  0.9672]]]]) \n",
      "\n",
      "The output is tensor([[[-2.4614]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.2901209890842438\n",
      "\n",
      "tensor([[[[-0.7375, -0.1019,  0.6942],\n",
      "          [-1.0270, -0.0266,  0.8746],\n",
      "          [-0.7008,  0.0677,  0.9672]]]]) \n",
      "\n",
      "The output is tensor([[[0.0101]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00010159037628909573\n",
      "\n",
      "tensor([[[[-0.7377, -0.1021,  0.6940],\n",
      "          [-1.0272, -0.0268,  0.8744],\n",
      "          [-0.7010,  0.0675,  0.9670]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.7377, -0.1021,  0.6940],\n",
      "          [-1.0272, -0.0268,  0.8744],\n",
      "          [-0.7010,  0.0675,  0.9670]]]]) \n",
      "\n",
      "### Epoch_31 ###\n",
      "\n",
      "The output is tensor([[[2.4742]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.2765132784843445\n",
      "\n",
      "tensor([[[[-0.7377, -0.0916,  0.7045],\n",
      "          [-1.0272, -0.0163,  0.8850],\n",
      "          [-0.7010,  0.0781,  0.9775]]]]) \n",
      "\n",
      "The output is tensor([[[-2.4957]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.25435322523117065\n",
      "\n",
      "tensor([[[[-0.7478, -0.1017,  0.7045],\n",
      "          [-1.0373, -0.0263,  0.8850],\n",
      "          [-0.7111,  0.0680,  0.9775]]]]) \n",
      "\n",
      "The output is tensor([[[0.0108]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0001176374134956859\n",
      "\n",
      "tensor([[[[-0.7480, -0.1019,  0.7043],\n",
      "          [-1.0375, -0.0266,  0.8847],\n",
      "          [-0.7113,  0.0677,  0.9773]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.7480, -0.1019,  0.7043],\n",
      "          [-1.0375, -0.0266,  0.8847],\n",
      "          [-0.7113,  0.0677,  0.9773]]]]) \n",
      "\n",
      "### Epoch_32 ###\n",
      "\n",
      "The output is tensor([[[2.5057]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.244337797164917\n",
      "\n",
      "tensor([[[[-0.7480, -0.0920,  0.7142],\n",
      "          [-1.0375, -0.0167,  0.8946],\n",
      "          [-0.7113,  0.0776,  0.9872]]]]) \n",
      "\n",
      "The output is tensor([[[-2.5278]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.22294574975967407\n",
      "\n",
      "tensor([[[[-0.7574, -0.1014,  0.7142],\n",
      "          [-1.0469, -0.0261,  0.8946],\n",
      "          [-0.7207,  0.0682,  0.9872]]]]) \n",
      "\n",
      "The output is tensor([[[0.0115]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0001334013359155506\n",
      "\n",
      "tensor([[[[-0.7577, -0.1017,  0.7140],\n",
      "          [-1.0472, -0.0263,  0.8944],\n",
      "          [-0.7210,  0.0680,  0.9870]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.7577, -0.1017,  0.7140],\n",
      "          [-1.0472, -0.0263,  0.8944],\n",
      "          [-0.7210,  0.0680,  0.9870]]]]) \n",
      "\n",
      "### Epoch_33 ###\n",
      "\n",
      "The output is tensor([[[2.5353]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.21595095098018646\n",
      "\n",
      "tensor([[[[-0.7577, -0.0924,  0.7233],\n",
      "          [-1.0472, -0.0170,  0.9037],\n",
      "          [-0.7210,  0.0773,  0.9963]]]]) \n",
      "\n",
      "The output is tensor([[[-2.5580]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.19537024199962616\n",
      "\n",
      "tensor([[[[-0.7665, -0.1012,  0.7233],\n",
      "          [-1.0560, -0.0259,  0.9037],\n",
      "          [-0.7298,  0.0684,  0.9963]]]]) \n",
      "\n",
      "The output is tensor([[[0.0122]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00014870618178974837\n",
      "\n",
      "tensor([[[[-0.7668, -0.1015,  0.7230],\n",
      "          [-1.0563, -0.0261,  0.9035],\n",
      "          [-0.7301,  0.0682,  0.9960]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.7668, -0.1015,  0.7230],\n",
      "          [-1.0563, -0.0261,  0.9035],\n",
      "          [-0.7301,  0.0682,  0.9960]]]]) \n",
      "\n",
      "### Epoch_34 ###\n",
      "\n",
      "The output is tensor([[[2.5631]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.190902978181839\n",
      "\n",
      "tensor([[[[-0.7668, -0.0927,  0.7318],\n",
      "          [-1.0563, -0.0174,  0.9122],\n",
      "          [-0.7301,  0.0769,  1.0048]]]]) \n",
      "\n",
      "The output is tensor([[[-2.5863]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.17116276919841766\n",
      "\n",
      "tensor([[[[-0.7750, -0.1010,  0.7318],\n",
      "          [-1.0645, -0.0257,  0.9122],\n",
      "          [-0.7383,  0.0686,  1.0048]]]]) \n",
      "\n",
      "The output is tensor([[[0.0128]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00016343685274478048\n",
      "\n",
      "tensor([[[[-0.7753, -0.1013,  0.7315],\n",
      "          [-1.0648, -0.0259,  0.9119],\n",
      "          [-0.7386,  0.0684,  1.0045]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.7753, -0.1013,  0.7315],\n",
      "          [-1.0648, -0.0259,  0.9119],\n",
      "          [-0.7386,  0.0684,  1.0045]]]]) \n",
      "\n",
      "### Epoch_35 ###\n",
      "\n",
      "The output is tensor([[[2.5891]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.16879834234714508\n",
      "\n",
      "tensor([[[[-0.7753, -0.0930,  0.7397],\n",
      "          [-1.0648, -0.0177,  0.9202],\n",
      "          [-0.7386,  0.0766,  1.0127]]]]) \n",
      "\n",
      "The output is tensor([[[-2.6128]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.1499154418706894\n",
      "\n",
      "tensor([[[[-0.7830, -0.1008,  0.7397],\n",
      "          [-1.0725, -0.0255,  0.9202],\n",
      "          [-0.7463,  0.0689,  1.0127]]]]) \n",
      "\n",
      "The output is tensor([[[0.0133]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0001774850970832631\n",
      "\n",
      "tensor([[[[-0.7833, -0.1010,  0.7395],\n",
      "          [-1.0728, -0.0257,  0.9199],\n",
      "          [-0.7466,  0.0686,  1.0125]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.7833, -0.1010,  0.7395],\n",
      "          [-1.0728, -0.0257,  0.9199],\n",
      "          [-0.7466,  0.0686,  1.0125]]]]) \n",
      "\n",
      "### Epoch_36 ###\n",
      "\n",
      "The output is tensor([[[2.6136]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.14928855001926422\n",
      "\n",
      "tensor([[[[-0.7833, -0.0933,  0.7472],\n",
      "          [-1.0728, -0.0180,  0.9276],\n",
      "          [-0.7466,  0.0763,  1.0202]]]]) \n",
      "\n",
      "The output is tensor([[[-2.6377]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.13126882910728455\n",
      "\n",
      "tensor([[[[-0.7906, -0.1006,  0.7472],\n",
      "          [-1.0800, -0.0252,  0.9276],\n",
      "          [-0.7538,  0.0691,  1.0202]]]]) \n",
      "\n",
      "The output is tensor([[[0.0138]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00019078960758633912\n",
      "\n",
      "tensor([[[[-0.7908, -0.1008,  0.7469],\n",
      "          [-1.0803, -0.0255,  0.9273],\n",
      "          [-0.7541,  0.0688,  1.0199]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.7908, -0.1008,  0.7469],\n",
      "          [-1.0803, -0.0255,  0.9273],\n",
      "          [-0.7541,  0.0688,  1.0199]]]]) \n",
      "\n",
      "### Epoch_37 ###\n",
      "\n",
      "The output is tensor([[[2.6366]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.13206630945205688\n",
      "\n",
      "tensor([[[[-0.7908, -0.0936,  0.7542],\n",
      "          [-1.0803, -0.0182,  0.9346],\n",
      "          [-0.7541,  0.0761,  1.0272]]]]) \n",
      "\n",
      "The output is tensor([[[-2.6610]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.11490757763385773\n",
      "\n",
      "tensor([[[[-0.7976, -0.1004,  0.7542],\n",
      "          [-1.0871, -0.0250,  0.9346],\n",
      "          [-0.7609,  0.0693,  1.0272]]]]) \n",
      "\n",
      "The output is tensor([[[0.0143]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00020329133258201182\n",
      "\n",
      "tensor([[[[-0.7979, -0.1006,  0.7539],\n",
      "          [-1.0874, -0.0253,  0.9343],\n",
      "          [-0.7612,  0.0690,  1.0269]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.7979, -0.1006,  0.7539],\n",
      "          [-1.0874, -0.0253,  0.9343],\n",
      "          [-0.7612,  0.0690,  1.0269]]]]) \n",
      "\n",
      "### Epoch_38 ###\n",
      "\n",
      "The output is tensor([[[2.6582]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.11686129122972488\n",
      "\n",
      "tensor([[[[-0.7979, -0.0938,  0.7607],\n",
      "          [-1.0874, -0.0185,  0.9412],\n",
      "          [-0.7612,  0.0758,  1.0337]]]]) \n",
      "\n",
      "The output is tensor([[[-2.6829]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.10055410116910934\n",
      "\n",
      "tensor([[[[-0.8042, -0.1001,  0.7607],\n",
      "          [-1.0937, -0.0248,  0.9412],\n",
      "          [-0.7675,  0.0695,  1.0337]]]]) \n",
      "\n",
      "The output is tensor([[[0.0147]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00021495406690519303\n",
      "\n",
      "tensor([[[[-0.8045, -0.1004,  0.7604],\n",
      "          [-1.0940, -0.0251,  0.9409],\n",
      "          [-0.7678,  0.0692,  1.0334]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8045, -0.1004,  0.7604],\n",
      "          [-1.0940, -0.0251,  0.9409],\n",
      "          [-0.7678,  0.0692,  1.0334]]]]) \n",
      "\n",
      "### Epoch_39 ###\n",
      "\n",
      "The output is tensor([[[2.6784]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.10343527793884277\n",
      "\n",
      "tensor([[[[-0.8045, -0.0940,  0.7669],\n",
      "          [-1.0940, -0.0187,  0.9473],\n",
      "          [-0.7678,  0.0756,  1.0399]]]]) \n",
      "\n",
      "The output is tensor([[[-2.7034]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.08796426653862\n",
      "\n",
      "tensor([[[[-0.8105, -0.0999,  0.7669],\n",
      "          [-1.1000, -0.0246,  0.9473],\n",
      "          [-0.7737,  0.0697,  1.0399]]]]) \n",
      "\n",
      "The output is tensor([[[0.0150]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00022575838374905288\n",
      "\n",
      "tensor([[[[-0.8108, -0.1002,  0.7666],\n",
      "          [-1.1003, -0.0249,  0.9470],\n",
      "          [-0.7740,  0.0694,  1.0396]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8108, -0.1002,  0.7666],\n",
      "          [-1.1003, -0.0249,  0.9470],\n",
      "          [-0.7740,  0.0694,  1.0396]]]]) \n",
      "\n",
      "### Epoch_40 ###\n",
      "\n",
      "The output is tensor([[[2.6974]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0915776714682579\n",
      "\n",
      "tensor([[[[-0.8108, -0.0942,  0.7726],\n",
      "          [-1.1003, -0.0189,  0.9530],\n",
      "          [-0.7740,  0.0754,  1.0456]]]]) \n",
      "\n",
      "The output is tensor([[[-2.7226]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.07692352682352066\n",
      "\n",
      "tensor([[[[-0.8163, -0.0997,  0.7726],\n",
      "          [-1.1058, -0.0244,  0.9530],\n",
      "          [-0.7796,  0.0699,  1.0456]]]]) \n",
      "\n",
      "The output is tensor([[[0.0154]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00023570253688376397\n",
      "\n",
      "tensor([[[[-0.8166, -0.1000,  0.7723],\n",
      "          [-1.1061, -0.0247,  0.9527],\n",
      "          [-0.7799,  0.0696,  1.0453]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8166, -0.1000,  0.7723],\n",
      "          [-1.1061, -0.0247,  0.9527],\n",
      "          [-0.7799,  0.0696,  1.0453]]]]) \n",
      "\n",
      "### Epoch_41 ###\n",
      "\n",
      "The output is tensor([[[2.7152]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.08110373467206955\n",
      "\n",
      "tensor([[[[-0.8166, -0.0943,  0.7780],\n",
      "          [-1.1061, -0.0190,  0.9584],\n",
      "          [-0.7799,  0.0753,  1.0510]]]]) \n",
      "\n",
      "The output is tensor([[[-2.7407]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.06724365800619125\n",
      "\n",
      "tensor([[[[-0.8218, -0.0995,  0.7780],\n",
      "          [-1.1113, -0.0242,  0.9584],\n",
      "          [-0.7851,  0.0701,  1.0510]]]]) \n",
      "\n",
      "The output is tensor([[[0.0156]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00024479671264998615\n",
      "\n",
      "tensor([[[[-0.8221, -0.0998,  0.7777],\n",
      "          [-1.1116, -0.0245,  0.9581],\n",
      "          [-0.7854,  0.0698,  1.0507]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8221, -0.0998,  0.7777],\n",
      "          [-1.1116, -0.0245,  0.9581],\n",
      "          [-0.7854,  0.0698,  1.0507]]]]) \n",
      "\n",
      "### Epoch_42 ###\n",
      "\n",
      "The output is tensor([[[2.7320]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.07185039669275284\n",
      "\n",
      "tensor([[[[-0.8221, -0.0945,  0.7831],\n",
      "          [-1.1116, -0.0192,  0.9635],\n",
      "          [-0.7854,  0.0752,  1.0561]]]]) \n",
      "\n",
      "The output is tensor([[[-2.7576]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.058758534491062164\n",
      "\n",
      "tensor([[[[-0.8270, -0.0993,  0.7831],\n",
      "          [-1.1165, -0.0240,  0.9635],\n",
      "          [-0.7903,  0.0703,  1.0561]]]]) \n",
      "\n",
      "The output is tensor([[[0.0159]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00025304939481429756\n",
      "\n",
      "tensor([[[[-0.8273, -0.0996,  0.7827],\n",
      "          [-1.1168, -0.0243,  0.9632],\n",
      "          [-0.7906,  0.0700,  1.0557]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8273, -0.0996,  0.7827],\n",
      "          [-1.1168, -0.0243,  0.9632],\n",
      "          [-0.7906,  0.0700,  1.0557]]]]) \n",
      "\n",
      "### Epoch_43 ###\n",
      "\n",
      "The output is tensor([[[2.7477]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0636737123131752\n",
      "\n",
      "tensor([[[[-0.8273, -0.0946,  0.7878],\n",
      "          [-1.1168, -0.0193,  0.9682],\n",
      "          [-0.7906,  0.0750,  1.0608]]]]) \n",
      "\n",
      "The output is tensor([[[-2.7735]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.051322463899850845\n",
      "\n",
      "tensor([[[[-0.8318, -0.0991,  0.7878],\n",
      "          [-1.1213, -0.0238,  0.9682],\n",
      "          [-0.7951,  0.0705,  1.0608]]]]) \n",
      "\n",
      "The output is tensor([[[0.0161]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002604605979286134\n",
      "\n",
      "tensor([[[[-0.8321, -0.0995,  0.7875],\n",
      "          [-1.1216, -0.0241,  0.9679],\n",
      "          [-0.7954,  0.0702,  1.0605]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8321, -0.0995,  0.7875],\n",
      "          [-1.1216, -0.0241,  0.9679],\n",
      "          [-0.7954,  0.0702,  1.0605]]]]) \n",
      "\n",
      "### Epoch_44 ###\n",
      "\n",
      "The output is tensor([[[2.7624]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.056446779519319534\n",
      "\n",
      "tensor([[[[-0.8321, -0.0947,  0.7922],\n",
      "          [-1.1216, -0.0194,  0.9726],\n",
      "          [-0.7954,  0.0749,  1.0652]]]]) \n",
      "\n",
      "The output is tensor([[[-2.7883]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.04480758681893349\n",
      "\n",
      "tensor([[[[-0.8364, -0.0989,  0.7922],\n",
      "          [-1.1259, -0.0236,  0.9726],\n",
      "          [-0.7997,  0.0707,  1.0652]]]]) \n",
      "\n",
      "The output is tensor([[[0.0163]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002670818939805031\n",
      "\n",
      "tensor([[[[-0.8367, -0.0993,  0.7919],\n",
      "          [-1.1262, -0.0239,  0.9723],\n",
      "          [-0.8000,  0.0704,  1.0649]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8367, -0.0993,  0.7919],\n",
      "          [-1.1262, -0.0239,  0.9723],\n",
      "          [-0.8000,  0.0704,  1.0649]]]]) \n",
      "\n",
      "### Epoch_45 ###\n",
      "\n",
      "The output is tensor([[[2.7763]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.05005835369229317\n",
      "\n",
      "tensor([[[[-0.8367, -0.0948,  0.7964],\n",
      "          [-1.1262, -0.0195,  0.9768],\n",
      "          [-0.8000,  0.0748,  1.0694]]]]) \n",
      "\n",
      "The output is tensor([[[-2.8023]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.039100948721170425\n",
      "\n",
      "tensor([[[[-0.8406, -0.0987,  0.7964],\n",
      "          [-1.1301, -0.0234,  0.9768],\n",
      "          [-0.8039,  0.0709,  1.0694]]]]) \n",
      "\n",
      "The output is tensor([[[0.0165]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00027293874882161617\n",
      "\n",
      "tensor([[[[-0.8410, -0.0991,  0.7960],\n",
      "          [-1.1305, -0.0237,  0.9765],\n",
      "          [-0.8043,  0.0706,  1.0690]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8410, -0.0991,  0.7960],\n",
      "          [-1.1305, -0.0237,  0.9765],\n",
      "          [-0.8043,  0.0706,  1.0690]]]]) \n",
      "\n",
      "### Epoch_46 ###\n",
      "\n",
      "The output is tensor([[[2.7893]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0444093756377697\n",
      "\n",
      "tensor([[[[-0.8410, -0.0949,  0.8002],\n",
      "          [-1.1305, -0.0195,  0.9807],\n",
      "          [-0.8043,  0.0748,  1.0732]]]]) \n",
      "\n",
      "The output is tensor([[[-2.8153]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.034104056656360626\n",
      "\n",
      "tensor([[[[-0.8447, -0.0985,  0.8002],\n",
      "          [-1.1342, -0.0232,  0.9807],\n",
      "          [-0.8080,  0.0711,  1.0732]]]]) \n",
      "\n",
      "The output is tensor([[[0.0167]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002780435315798968\n",
      "\n",
      "tensor([[[[-0.8450, -0.0989,  0.7999],\n",
      "          [-1.1345, -0.0236,  0.9803],\n",
      "          [-0.8083,  0.0707,  1.0729]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8450, -0.0989,  0.7999],\n",
      "          [-1.1345, -0.0236,  0.9803],\n",
      "          [-0.8083,  0.0707,  1.0729]]]]) \n",
      "\n",
      "### Epoch_47 ###\n",
      "\n",
      "The output is tensor([[[2.8015]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.03941348195075989\n",
      "\n",
      "tensor([[[[-0.8450, -0.0949,  0.8039],\n",
      "          [-1.1345, -0.0196,  0.9843],\n",
      "          [-0.8083,  0.0747,  1.0769]]]]) \n",
      "\n",
      "The output is tensor([[[-2.8276]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.029729405418038368\n",
      "\n",
      "tensor([[[[-0.8485, -0.0984,  0.8039],\n",
      "          [-1.1379, -0.0230,  0.9843],\n",
      "          [-0.8117,  0.0713,  1.0769]]]]) \n",
      "\n",
      "The output is tensor([[[0.0168]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002824338444042951\n",
      "\n",
      "tensor([[[[-0.8488, -0.0987,  0.8035],\n",
      "          [-1.1383, -0.0234,  0.9840],\n",
      "          [-0.8121,  0.0709,  1.0765]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8488, -0.0987,  0.8035],\n",
      "          [-1.1383, -0.0234,  0.9840],\n",
      "          [-0.8121,  0.0709,  1.0765]]]]) \n",
      "\n",
      "### Epoch_48 ###\n",
      "\n",
      "The output is tensor([[[2.8129]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.03499407321214676\n",
      "\n",
      "tensor([[[[-0.8488, -0.0950,  0.8073],\n",
      "          [-1.1383, -0.0196,  0.9877],\n",
      "          [-0.8121,  0.0747,  1.0803]]]]) \n",
      "\n",
      "The output is tensor([[[-2.8391]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.02590143121778965\n",
      "\n",
      "tensor([[[[-0.8520, -0.0982,  0.8073],\n",
      "          [-1.1415, -0.0228,  0.9877],\n",
      "          [-0.8153,  0.0715,  1.0803]]]]) \n",
      "\n",
      "The output is tensor([[[0.0169]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00028615634073503315\n",
      "\n",
      "tensor([[[[-0.8523, -0.0985,  0.8069],\n",
      "          [-1.1418, -0.0232,  0.9874],\n",
      "          [-0.8156,  0.0711,  1.0800]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8523, -0.0985,  0.8069],\n",
      "          [-1.1418, -0.0232,  0.9874],\n",
      "          [-0.8156,  0.0711,  1.0800]]]]) \n",
      "\n",
      "### Epoch_49 ###\n",
      "\n",
      "The output is tensor([[[2.8237]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.03108355589210987\n",
      "\n",
      "tensor([[[[-0.8523, -0.0950,  0.8105],\n",
      "          [-1.1418, -0.0197,  0.9909],\n",
      "          [-0.8156,  0.0746,  1.0835]]]]) \n",
      "\n",
      "The output is tensor([[[-2.8498]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.02255241572856903\n",
      "\n",
      "tensor([[[[-0.8553, -0.0980,  0.8105],\n",
      "          [-1.1448, -0.0227,  0.9909],\n",
      "          [-0.8186,  0.0716,  1.0835]]]]) \n",
      "\n",
      "The output is tensor([[[0.0170]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002892337797675282\n",
      "\n",
      "tensor([[[[-0.8557, -0.0983,  0.8101],\n",
      "          [-1.1452, -0.0230,  0.9906],\n",
      "          [-0.8190,  0.0713,  1.0831]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8557, -0.0983,  0.8101],\n",
      "          [-1.1452, -0.0230,  0.9906],\n",
      "          [-0.8190,  0.0713,  1.0831]]]]) \n",
      "\n",
      "### Epoch_50 ###\n",
      "\n",
      "The output is tensor([[[2.8338]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.027622492983937263\n",
      "\n",
      "tensor([[[[-0.8557, -0.0950,  0.8135],\n",
      "          [-1.1452, -0.0197,  0.9939],\n",
      "          [-0.8190,  0.0746,  1.0865]]]]) \n",
      "\n",
      "The output is tensor([[[-2.8599]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.01962386816740036\n",
      "\n",
      "tensor([[[[-0.8585, -0.0978,  0.8135],\n",
      "          [-1.1480, -0.0225,  0.9939],\n",
      "          [-0.8218,  0.0718,  1.0865]]]]) \n",
      "\n",
      "The output is tensor([[[0.0171]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002917124656960368\n",
      "\n",
      "tensor([[[[-0.8588, -0.0981,  0.8131],\n",
      "          [-1.1483, -0.0228,  0.9935],\n",
      "          [-0.8221,  0.0715,  1.0861]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8588, -0.0981,  0.8131],\n",
      "          [-1.1483, -0.0228,  0.9935],\n",
      "          [-0.8221,  0.0715,  1.0861]]]]) \n",
      "\n",
      "### Epoch_51 ###\n",
      "\n",
      "The output is tensor([[[2.8433]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.02455822005867958\n",
      "\n",
      "tensor([[[[-0.8588, -0.0950,  0.8162],\n",
      "          [-1.1483, -0.0197,  0.9967],\n",
      "          [-0.8221,  0.0746,  1.0893]]]]) \n",
      "\n",
      "The output is tensor([[[-2.8694]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.017063703387975693\n",
      "\n",
      "tensor([[[[-0.8614, -0.0976,  0.8162],\n",
      "          [-1.1509, -0.0223,  0.9967],\n",
      "          [-0.8247,  0.0720,  1.0893]]]]) \n",
      "\n",
      "The output is tensor([[[0.0171]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002936131495516747\n",
      "\n",
      "tensor([[[[-0.8618, -0.0980,  0.8159],\n",
      "          [-1.1513, -0.0226,  0.9963],\n",
      "          [-0.8251,  0.0717,  1.0889]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8618, -0.0980,  0.8159],\n",
      "          [-1.1513, -0.0226,  0.9963],\n",
      "          [-0.8251,  0.0717,  1.0889]]]]) \n",
      "\n",
      "### Epoch_52 ###\n",
      "\n",
      "The output is tensor([[[2.8522]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.021844619885087013\n",
      "\n",
      "tensor([[[[-0.8618, -0.0950,  0.8189],\n",
      "          [-1.1513, -0.0197,  0.9993],\n",
      "          [-0.8251,  0.0746,  1.0919]]]]) \n",
      "\n",
      "The output is tensor([[[-2.8782]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.014826574362814426\n",
      "\n",
      "tensor([[[[-0.8642, -0.0974,  0.8189],\n",
      "          [-1.1537, -0.0221,  0.9993],\n",
      "          [-0.8275,  0.0722,  1.0919]]]]) \n",
      "\n",
      "The output is tensor([[[0.0172]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002949751215055585\n",
      "\n",
      "tensor([[[[-0.8646, -0.0978,  0.8185],\n",
      "          [-1.1541, -0.0225,  0.9989],\n",
      "          [-0.8279,  0.0718,  1.0915]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8646, -0.0978,  0.8185],\n",
      "          [-1.1541, -0.0225,  0.9989],\n",
      "          [-0.8279,  0.0718,  1.0915]]]]) \n",
      "\n",
      "### Epoch_53 ###\n",
      "\n",
      "The output is tensor([[[2.8606]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.01944073848426342\n",
      "\n",
      "tensor([[[[-0.8646, -0.0950,  0.8213],\n",
      "          [-1.1541, -0.0197,  1.0017],\n",
      "          [-0.8279,  0.0746,  1.0943]]]]) \n",
      "\n",
      "The output is tensor([[[-2.8865]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.012872644700109959\n",
      "\n",
      "tensor([[[[-0.8668, -0.0973,  0.8213],\n",
      "          [-1.1563, -0.0219,  1.0017],\n",
      "          [-0.8301,  0.0724,  1.0943]]]]) \n",
      "\n",
      "The output is tensor([[[0.0172]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002958479744847864\n",
      "\n",
      "tensor([[[[-0.8672, -0.0976,  0.8210],\n",
      "          [-1.1567, -0.0223,  1.0014],\n",
      "          [-0.8305,  0.0720,  1.0940]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8672, -0.0976,  0.8210],\n",
      "          [-1.1567, -0.0223,  1.0014],\n",
      "          [-0.8305,  0.0720,  1.0940]]]]) \n",
      "\n",
      "### Epoch_54 ###\n",
      "\n",
      "The output is tensor([[[2.8684]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.017310691997408867\n",
      "\n",
      "tensor([[[[-0.8672, -0.0950,  0.8236],\n",
      "          [-1.1567, -0.0197,  1.0040],\n",
      "          [-0.8305,  0.0746,  1.0966]]]]) \n",
      "\n",
      "The output is tensor([[[-2.8943]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.011166648007929325\n",
      "\n",
      "tensor([[[[-0.8693, -0.0971,  0.8236],\n",
      "          [-1.1588, -0.0218,  1.0040],\n",
      "          [-0.8326,  0.0725,  1.0966]]]]) \n",
      "\n",
      "The output is tensor([[[0.0172]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00029624998569488525\n",
      "\n",
      "tensor([[[[-0.8696, -0.0974,  0.8232],\n",
      "          [-1.1591, -0.0221,  1.0037],\n",
      "          [-0.8329,  0.0722,  1.0963]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8696, -0.0974,  0.8232],\n",
      "          [-1.1591, -0.0221,  1.0037],\n",
      "          [-0.8329,  0.0722,  1.0963]]]]) \n",
      "\n",
      "### Epoch_55 ###\n",
      "\n",
      "The output is tensor([[[2.8758]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.015422527678310871\n",
      "\n",
      "tensor([[[[-0.8696, -0.0950,  0.8257],\n",
      "          [-1.1591, -0.0196,  1.0062],\n",
      "          [-0.8329,  0.0747,  1.0987]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9016]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.009678219445049763\n",
      "\n",
      "tensor([[[[-0.8716, -0.0969,  0.8257],\n",
      "          [-1.1611, -0.0216,  1.0062],\n",
      "          [-0.8349,  0.0727,  1.0987]]]]) \n",
      "\n",
      "The output is tensor([[[0.0172]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00029620894929394126\n",
      "\n",
      "tensor([[[[-0.8719, -0.0973,  0.8254],\n",
      "          [-1.1614, -0.0219,  1.0058],\n",
      "          [-0.8352,  0.0724,  1.0984]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8719, -0.0973,  0.8254],\n",
      "          [-1.1614, -0.0219,  1.0058],\n",
      "          [-0.8352,  0.0724,  1.0984]]]]) \n",
      "\n",
      "### Epoch_56 ###\n",
      "\n",
      "The output is tensor([[[2.8827]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.013748225755989552\n",
      "\n",
      "tensor([[[[-0.8719, -0.0949,  0.8277],\n",
      "          [-1.1614, -0.0196,  1.0082],\n",
      "          [-0.8352,  0.0747,  1.1007]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9085]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00837998278439045\n",
      "\n",
      "tensor([[[[-0.8738, -0.0968,  0.8277],\n",
      "          [-1.1633, -0.0214,  1.0082],\n",
      "          [-0.8371,  0.0729,  1.1007]]]]) \n",
      "\n",
      "The output is tensor([[[0.0172]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00029578234534710646\n",
      "\n",
      "tensor([[[[-0.8741, -0.0971,  0.8274],\n",
      "          [-1.1636, -0.0218,  1.0078],\n",
      "          [-0.8374,  0.0725,  1.1004]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8741, -0.0971,  0.8274],\n",
      "          [-1.1636, -0.0218,  1.0078],\n",
      "          [-0.8374,  0.0725,  1.1004]]]]) \n",
      "\n",
      "### Epoch_57 ###\n",
      "\n",
      "The output is tensor([[[2.8893]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.012263071723282337\n",
      "\n",
      "tensor([[[[-0.8741, -0.0949,  0.8296],\n",
      "          [-1.1636, -0.0196,  1.0100],\n",
      "          [-0.8374,  0.0747,  1.1026]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9149]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0072484929114580154\n",
      "\n",
      "tensor([[[[-0.8758, -0.0966,  0.8296],\n",
      "          [-1.1653, -0.0213,  1.0100],\n",
      "          [-0.8391,  0.0730,  1.1026]]]]) \n",
      "\n",
      "The output is tensor([[[0.0172]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002949751215055585\n",
      "\n",
      "tensor([[[[-0.8762, -0.0969,  0.8293],\n",
      "          [-1.1657, -0.0216,  1.0097],\n",
      "          [-0.8395,  0.0727,  1.1023]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8762, -0.0969,  0.8293],\n",
      "          [-1.1657, -0.0216,  1.0097],\n",
      "          [-0.8395,  0.0727,  1.1023]]]]) \n",
      "\n",
      "### Epoch_58 ###\n",
      "\n",
      "The output is tensor([[[2.8954]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.01094514038413763\n",
      "\n",
      "tensor([[[[-0.8762, -0.0948,  0.8314],\n",
      "          [-1.1657, -0.0195,  1.0118],\n",
      "          [-0.8395,  0.0748,  1.1044]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9209]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.006262716371566057\n",
      "\n",
      "tensor([[[[-0.8778, -0.0964,  0.8314],\n",
      "          [-1.1672, -0.0211,  1.0118],\n",
      "          [-0.8410,  0.0732,  1.1044]]]]) \n",
      "\n",
      "The output is tensor([[[0.0171]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00029382153297774494\n",
      "\n",
      "tensor([[[[-0.8781, -0.0968,  0.8310],\n",
      "          [-1.1676, -0.0214,  1.0114],\n",
      "          [-0.8414,  0.0729,  1.1040]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8781, -0.0968,  0.8310],\n",
      "          [-1.1676, -0.0214,  1.0114],\n",
      "          [-0.8414,  0.0729,  1.1040]]]]) \n",
      "\n",
      "### Epoch_59 ###\n",
      "\n",
      "The output is tensor([[[2.9011]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.009775332175195217\n",
      "\n",
      "tensor([[[[-0.8781, -0.0948,  0.8330],\n",
      "          [-1.1676, -0.0195,  1.0134],\n",
      "          [-0.8414,  0.0748,  1.1060]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9265]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.005404656287282705\n",
      "\n",
      "tensor([[[[-0.8796, -0.0963,  0.8330],\n",
      "          [-1.1691, -0.0209,  1.0134],\n",
      "          [-0.8429,  0.0734,  1.1060]]]]) \n",
      "\n",
      "The output is tensor([[[0.0171]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002923521096818149\n",
      "\n",
      "tensor([[[[-0.8799, -0.0966,  0.8326],\n",
      "          [-1.1694, -0.0213,  1.0131],\n",
      "          [-0.8432,  0.0730,  1.1057]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8799, -0.0966,  0.8326],\n",
      "          [-1.1694, -0.0213,  1.0131],\n",
      "          [-0.8432,  0.0730,  1.1057]]]]) \n",
      "\n",
      "### Epoch_60 ###\n",
      "\n",
      "The output is tensor([[[2.9065]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.008736391551792622\n",
      "\n",
      "tensor([[[[-0.8799, -0.0947,  0.8345],\n",
      "          [-1.1694, -0.0194,  1.0149],\n",
      "          [-0.8432,  0.0749,  1.1075]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9317]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.004658151883631945\n",
      "\n",
      "tensor([[[[-0.8813, -0.0961,  0.8345],\n",
      "          [-1.1708, -0.0208,  1.0149],\n",
      "          [-0.8446,  0.0735,  1.1075]]]]) \n",
      "\n",
      "The output is tensor([[[0.0170]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002905855653807521\n",
      "\n",
      "tensor([[[[-0.8816, -0.0964,  0.8342],\n",
      "          [-1.1711, -0.0211,  1.0146],\n",
      "          [-0.8449,  0.0732,  1.1072]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8816, -0.0964,  0.8342],\n",
      "          [-1.1711, -0.0211,  1.0146],\n",
      "          [-0.8449,  0.0732,  1.1072]]]]) \n",
      "\n",
      "### Epoch_61 ###\n",
      "\n",
      "The output is tensor([[[2.9116]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.007813317701220512\n",
      "\n",
      "tensor([[[[-0.8816, -0.0947,  0.8359],\n",
      "          [-1.1711, -0.0193,  1.0164],\n",
      "          [-0.8449,  0.0750,  1.1090]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9367]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.004009231459349394\n",
      "\n",
      "tensor([[[[-0.8829, -0.0959,  0.8359],\n",
      "          [-1.1724, -0.0206,  1.0164],\n",
      "          [-0.8462,  0.0737,  1.1090]]]]) \n",
      "\n",
      "The output is tensor([[[0.0170]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00028856107383035123\n",
      "\n",
      "tensor([[[[-0.8832, -0.0963,  0.8356],\n",
      "          [-1.1727, -0.0209,  1.0160],\n",
      "          [-0.8465,  0.0734,  1.1086]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8832, -0.0963,  0.8356],\n",
      "          [-1.1727, -0.0209,  1.0160],\n",
      "          [-0.8465,  0.0734,  1.1086]]]]) \n",
      "\n",
      "### Epoch_62 ###\n",
      "\n",
      "The output is tensor([[[2.9164]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.006992874667048454\n",
      "\n",
      "tensor([[[[-0.8832, -0.0946,  0.8373],\n",
      "          [-1.1727, -0.0193,  1.0177],\n",
      "          [-0.8465,  0.0750,  1.1103]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9413]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0034455880522727966\n",
      "\n",
      "tensor([[[[-0.8844, -0.0958,  0.8373],\n",
      "          [-1.1739, -0.0205,  1.0177],\n",
      "          [-0.8477,  0.0739,  1.1103]]]]) \n",
      "\n",
      "The output is tensor([[[0.0169]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002862974943127483\n",
      "\n",
      "tensor([[[[-0.8847, -0.0961,  0.8369],\n",
      "          [-1.1742, -0.0208,  1.0174],\n",
      "          [-0.8480,  0.0735,  1.1099]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8847, -0.0961,  0.8369],\n",
      "          [-1.1742, -0.0208,  1.0174],\n",
      "          [-0.8480,  0.0735,  1.1099]]]]) \n",
      "\n",
      "### Epoch_63 ###\n",
      "\n",
      "The output is tensor([[[2.9209]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.006263319868594408\n",
      "\n",
      "tensor([[[[-0.8847, -0.0945,  0.8385],\n",
      "          [-1.1742, -0.0192,  1.0190],\n",
      "          [-0.8480,  0.0751,  1.1115]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9456]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.002956477692350745\n",
      "\n",
      "tensor([[[[-0.8858, -0.0956,  0.8385],\n",
      "          [-1.1753, -0.0203,  1.0190],\n",
      "          [-0.8491,  0.0740,  1.1115]]]]) \n",
      "\n",
      "The output is tensor([[[0.0168]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00028381787706166506\n",
      "\n",
      "tensor([[[[-0.8862, -0.0960,  0.8382],\n",
      "          [-1.1757, -0.0206,  1.0186],\n",
      "          [-0.8494,  0.0737,  1.1112]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8862, -0.0960,  0.8382],\n",
      "          [-1.1757, -0.0206,  1.0186],\n",
      "          [-0.8494,  0.0737,  1.1112]]]]) \n",
      "\n",
      "### Epoch_64 ###\n",
      "\n",
      "The output is tensor([[[2.9251]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.005614176392555237\n",
      "\n",
      "tensor([[[[-0.8862, -0.0945,  0.8397],\n",
      "          [-1.1757, -0.0191,  1.0201],\n",
      "          [-0.8494,  0.0752,  1.1127]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9497]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0025323573499917984\n",
      "\n",
      "tensor([[[[-0.8872, -0.0955,  0.8397],\n",
      "          [-1.1767, -0.0201,  1.0201],\n",
      "          [-0.8505,  0.0742,  1.1127]]]]) \n",
      "\n",
      "The output is tensor([[[0.0168]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002811371232382953\n",
      "\n",
      "tensor([[[[-0.8875, -0.0958,  0.8393],\n",
      "          [-1.1770, -0.0205,  1.0198],\n",
      "          [-0.8508,  0.0738,  1.1124]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8875, -0.0958,  0.8393],\n",
      "          [-1.1770, -0.0205,  1.0198],\n",
      "          [-0.8508,  0.0738,  1.1124]]]]) \n",
      "\n",
      "### Epoch_65 ###\n",
      "\n",
      "The output is tensor([[[2.9290]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.005036478396505117\n",
      "\n",
      "tensor([[[[-0.8875, -0.0944,  0.8408],\n",
      "          [-1.1770, -0.0191,  1.0212],\n",
      "          [-0.8508,  0.0752,  1.1138]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9535]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.002165041631087661\n",
      "\n",
      "tensor([[[[-0.8884, -0.0953,  0.8408],\n",
      "          [-1.1779, -0.0200,  1.0212],\n",
      "          [-0.8517,  0.0743,  1.1138]]]]) \n",
      "\n",
      "The output is tensor([[[0.0167]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00027827813755720854\n",
      "\n",
      "tensor([[[[-0.8888, -0.0956,  0.8404],\n",
      "          [-1.1783, -0.0203,  1.0209],\n",
      "          [-0.8521,  0.0740,  1.1134]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8888, -0.0956,  0.8404],\n",
      "          [-1.1783, -0.0203,  1.0209],\n",
      "          [-0.8521,  0.0740,  1.1134]]]]) \n",
      "\n",
      "### Epoch_66 ###\n",
      "\n",
      "The output is tensor([[[2.9328]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00452195480465889\n",
      "\n",
      "tensor([[[[-0.8888, -0.0943,  0.8418],\n",
      "          [-1.1783, -0.0190,  1.0222],\n",
      "          [-0.8521,  0.0753,  1.1148]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9570]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0018472151132300496\n",
      "\n",
      "tensor([[[[-0.8896, -0.0952,  0.8418],\n",
      "          [-1.1791, -0.0198,  1.0222],\n",
      "          [-0.8529,  0.0745,  1.1148]]]]) \n",
      "\n",
      "The output is tensor([[[0.0166]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00027525972109287977\n",
      "\n",
      "tensor([[[[-0.8900, -0.0955,  0.8414],\n",
      "          [-1.1794, -0.0202,  1.0219],\n",
      "          [-0.8532,  0.0741,  1.1145]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8900, -0.0955,  0.8414],\n",
      "          [-1.1794, -0.0202,  1.0219],\n",
      "          [-0.8532,  0.0741,  1.1145]]]]) \n",
      "\n",
      "### Epoch_67 ###\n",
      "\n",
      "The output is tensor([[[2.9363]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.004063488449901342\n",
      "\n",
      "tensor([[[[-0.8900, -0.0942,  0.8427],\n",
      "          [-1.1794, -0.0189,  1.0232],\n",
      "          [-0.8532,  0.0754,  1.1157]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9603]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.001572573441080749\n",
      "\n",
      "tensor([[[[-0.8907, -0.0950,  0.8427],\n",
      "          [-1.1802, -0.0197,  1.0232],\n",
      "          [-0.8540,  0.0746,  1.1157]]]]) \n",
      "\n",
      "The output is tensor([[[0.0165]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00027210041298530996\n",
      "\n",
      "tensor([[[[-0.8911, -0.0953,  0.8424],\n",
      "          [-1.1806, -0.0200,  1.0228],\n",
      "          [-0.8544,  0.0743,  1.1154]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8911, -0.0953,  0.8424],\n",
      "          [-1.1806, -0.0200,  1.0228],\n",
      "          [-0.8544,  0.0743,  1.1154]]]]) \n",
      "\n",
      "### Epoch_68 ###\n",
      "\n",
      "The output is tensor([[[2.9395]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0036547882482409477\n",
      "\n",
      "tensor([[[[-0.8911, -0.0941,  0.8436],\n",
      "          [-1.1806, -0.0188,  1.0240],\n",
      "          [-0.8544,  0.0755,  1.1166]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9635]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0013355398550629616\n",
      "\n",
      "tensor([[[[-0.8918, -0.0949,  0.8436],\n",
      "          [-1.1813, -0.0195,  1.0240],\n",
      "          [-0.8551,  0.0748,  1.1166]]]]) \n",
      "\n",
      "The output is tensor([[[0.0164]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00026882640668191016\n",
      "\n",
      "tensor([[[[-0.8921, -0.0952,  0.8433],\n",
      "          [-1.1816, -0.0199,  1.0237],\n",
      "          [-0.8554,  0.0744,  1.1163]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8921, -0.0952,  0.8433],\n",
      "          [-1.1816, -0.0199,  1.0237],\n",
      "          [-0.8554,  0.0744,  1.1163]]]]) \n",
      "\n",
      "### Epoch_69 ###\n",
      "\n",
      "The output is tensor([[[2.9426]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0032902166713029146\n",
      "\n",
      "tensor([[[[-0.8921, -0.0940,  0.8444],\n",
      "          [-1.1816, -0.0187,  1.0248],\n",
      "          [-0.8554,  0.0756,  1.1174]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9664]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0011312103597447276\n",
      "\n",
      "tensor([[[[-0.8928, -0.0947,  0.8444],\n",
      "          [-1.1823, -0.0194,  1.0248],\n",
      "          [-0.8561,  0.0749,  1.1174]]]]) \n",
      "\n",
      "The output is tensor([[[0.0163]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002654168347362429\n",
      "\n",
      "tensor([[[[-0.8931, -0.0950,  0.8441],\n",
      "          [-1.1826, -0.0197,  1.0245],\n",
      "          [-0.8564,  0.0746,  1.1171]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8931, -0.0950,  0.8441],\n",
      "          [-1.1826, -0.0197,  1.0245],\n",
      "          [-0.8564,  0.0746,  1.1171]]]]) \n",
      "\n",
      "### Epoch_70 ###\n",
      "\n",
      "The output is tensor([[[2.9455]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0029648062773048878\n",
      "\n",
      "tensor([[[[-0.8931, -0.0940,  0.8452],\n",
      "          [-1.1826, -0.0186,  1.0256],\n",
      "          [-0.8564,  0.0757,  1.1182]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9691]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0009553995332680643\n",
      "\n",
      "tensor([[[[-0.8938, -0.0946,  0.8452],\n",
      "          [-1.1832, -0.0192,  1.0256],\n",
      "          [-0.8570,  0.0751,  1.1182]]]]) \n",
      "\n",
      "The output is tensor([[[0.0162]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00026190938660874963\n",
      "\n",
      "tensor([[[[-0.8941, -0.0949,  0.8449],\n",
      "          [-1.1836, -0.0196,  1.0253],\n",
      "          [-0.8574,  0.0747,  1.1179]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8941, -0.0949,  0.8449],\n",
      "          [-1.1836, -0.0196,  1.0253],\n",
      "          [-0.8574,  0.0747,  1.1179]]]]) \n",
      "\n",
      "### Epoch_71 ###\n",
      "\n",
      "The output is tensor([[[2.9483]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.002674233401194215\n",
      "\n",
      "tensor([[[[-0.8941, -0.0939,  0.8459],\n",
      "          [-1.1836, -0.0185,  1.0263],\n",
      "          [-0.8574,  0.0758,  1.1189]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9716]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.000804337440058589\n",
      "\n",
      "tensor([[[[-0.8946, -0.0944,  0.8459],\n",
      "          [-1.1841, -0.0191,  1.0263],\n",
      "          [-0.8579,  0.0752,  1.1189]]]]) \n",
      "\n",
      "The output is tensor([[[0.0161]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002583409659564495\n",
      "\n",
      "tensor([[[[-0.8950, -0.0947,  0.8456],\n",
      "          [-1.1845, -0.0194,  1.0260],\n",
      "          [-0.8583,  0.0749,  1.1186]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8950, -0.0947,  0.8456],\n",
      "          [-1.1845, -0.0194,  1.0260],\n",
      "          [-0.8583,  0.0749,  1.1186]]]]) \n",
      "\n",
      "### Epoch_72 ###\n",
      "\n",
      "The output is tensor([[[2.9509]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.002414526417851448\n",
      "\n",
      "tensor([[[[-0.8950, -0.0938,  0.8466],\n",
      "          [-1.1845, -0.0184,  1.0270],\n",
      "          [-0.8583,  0.0759,  1.1196]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9740]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0006748239393346012\n",
      "\n",
      "tensor([[[[-0.8955, -0.0943,  0.8466],\n",
      "          [-1.1850, -0.0190,  1.0270],\n",
      "          [-0.8588,  0.0753,  1.1196]]]]) \n",
      "\n",
      "The output is tensor([[[0.0160]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002546980686020106\n",
      "\n",
      "tensor([[[[-0.8958, -0.0946,  0.8462],\n",
      "          [-1.1853, -0.0193,  1.0267],\n",
      "          [-0.8591,  0.0750,  1.1192]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8958, -0.0946,  0.8462],\n",
      "          [-1.1853, -0.0193,  1.0267],\n",
      "          [-0.8591,  0.0750,  1.1192]]]]) \n",
      "\n",
      "### Epoch_73 ###\n",
      "\n",
      "The output is tensor([[[2.9533]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.002182315569370985\n",
      "\n",
      "tensor([[[[-0.8958, -0.0937,  0.8472],\n",
      "          [-1.1853, -0.0183,  1.0276],\n",
      "          [-0.8591,  0.0760,  1.1202]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9763]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.000563963723834604\n",
      "\n",
      "tensor([[[[-0.8963, -0.0941,  0.8472],\n",
      "          [-1.1858, -0.0188,  1.0276],\n",
      "          [-0.8596,  0.0755,  1.1202]]]]) \n",
      "\n",
      "The output is tensor([[[0.0158]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00025098660262301564\n",
      "\n",
      "tensor([[[[-0.8966, -0.0945,  0.8469],\n",
      "          [-1.1861, -0.0191,  1.0273],\n",
      "          [-0.8599,  0.0752,  1.1199]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8966, -0.0945,  0.8469],\n",
      "          [-1.1861, -0.0191,  1.0273],\n",
      "          [-0.8599,  0.0752,  1.1199]]]]) \n",
      "\n",
      "### Epoch_74 ###\n",
      "\n",
      "The output is tensor([[[2.9556]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.001974471379071474\n",
      "\n",
      "tensor([[[[-0.8966, -0.0936,  0.8477],\n",
      "          [-1.1861, -0.0182,  1.0282],\n",
      "          [-0.8599,  0.0761,  1.1207]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9783]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00046929376549087465\n",
      "\n",
      "tensor([[[[-0.8970, -0.0940,  0.8477],\n",
      "          [-1.1865, -0.0187,  1.0282],\n",
      "          [-0.8603,  0.0756,  1.1207]]]]) \n",
      "\n",
      "The output is tensor([[[0.0157]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00024723116075620055\n",
      "\n",
      "tensor([[[[-0.8973, -0.0943,  0.8474],\n",
      "          [-1.1868, -0.0190,  1.0279],\n",
      "          [-0.8606,  0.0753,  1.1204]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8973, -0.0943,  0.8474],\n",
      "          [-1.1868, -0.0190,  1.0279],\n",
      "          [-0.8606,  0.0753,  1.1204]]]]) \n",
      "\n",
      "### Epoch_75 ###\n",
      "\n",
      "The output is tensor([[[2.9577]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0017884215340018272\n",
      "\n",
      "tensor([[[[-0.8973, -0.0935,  0.8483],\n",
      "          [-1.1868, -0.0181,  1.0287],\n",
      "          [-0.8606,  0.0762,  1.1213]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9803]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.000388637010473758\n",
      "\n",
      "tensor([[[[-0.8977, -0.0939,  0.8483],\n",
      "          [-1.1872, -0.0185,  1.0287],\n",
      "          [-0.8610,  0.0758,  1.1213]]]]) \n",
      "\n",
      "The output is tensor([[[0.0156]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00024343332916032523\n",
      "\n",
      "tensor([[[[-0.8981, -0.0942,  0.8480],\n",
      "          [-1.1875, -0.0189,  1.0284],\n",
      "          [-0.8613,  0.0754,  1.1210]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8981, -0.0942,  0.8480],\n",
      "          [-1.1875, -0.0189,  1.0284],\n",
      "          [-0.8613,  0.0754,  1.1210]]]]) \n",
      "\n",
      "### Epoch_76 ###\n",
      "\n",
      "The output is tensor([[[2.9597]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0016216801013797522\n",
      "\n",
      "tensor([[[[-0.8981, -0.0934,  0.8488],\n",
      "          [-1.1875, -0.0180,  1.0292],\n",
      "          [-0.8613,  0.0763,  1.1218]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9821]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0003201365761924535\n",
      "\n",
      "tensor([[[[-0.8984, -0.0937,  0.8488],\n",
      "          [-1.1879, -0.0184,  1.0292],\n",
      "          [-0.8617,  0.0759,  1.1218]]]]) \n",
      "\n",
      "The output is tensor([[[0.0155]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00023960215912666172\n",
      "\n",
      "tensor([[[[-0.8987, -0.0940,  0.8485],\n",
      "          [-1.1882, -0.0187,  1.0289],\n",
      "          [-0.8620,  0.0756,  1.1215]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8987, -0.0940,  0.8485],\n",
      "          [-1.1882, -0.0187,  1.0289],\n",
      "          [-0.8620,  0.0756,  1.1215]]]]) \n",
      "\n",
      "### Epoch_77 ###\n",
      "\n",
      "The output is tensor([[[2.9616]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0014721573097631335\n",
      "\n",
      "tensor([[[[-0.8987, -0.0933,  0.8492],\n",
      "          [-1.1882, -0.0179,  1.0297],\n",
      "          [-0.8620,  0.0764,  1.1222]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9838]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002621100575197488\n",
      "\n",
      "tensor([[[[-0.8990, -0.0936,  0.8492],\n",
      "          [-1.1885, -0.0183,  1.0297],\n",
      "          [-0.8623,  0.0760,  1.1222]]]]) \n",
      "\n",
      "The output is tensor([[[0.0154]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00023575378872919828\n",
      "\n",
      "tensor([[[[-0.8993, -0.0939,  0.8489],\n",
      "          [-1.1888, -0.0186,  1.0293],\n",
      "          [-0.8626,  0.0757,  1.1219]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8993, -0.0939,  0.8489],\n",
      "          [-1.1888, -0.0186,  1.0293],\n",
      "          [-0.8626,  0.0757,  1.1219]]]]) \n",
      "\n",
      "### Epoch_78 ###\n",
      "\n",
      "The output is tensor([[[2.9634]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.001337980618700385\n",
      "\n",
      "tensor([[[[-0.8993, -0.0932,  0.8496],\n",
      "          [-1.1888, -0.0178,  1.0301],\n",
      "          [-0.8626,  0.0765,  1.1227]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9854]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002131471992470324\n",
      "\n",
      "tensor([[[[-0.8996, -0.0935,  0.8496],\n",
      "          [-1.1891, -0.0181,  1.0301],\n",
      "          [-0.8629,  0.0762,  1.1227]]]]) \n",
      "\n",
      "The output is tensor([[[0.0152]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002318966289749369\n",
      "\n",
      "tensor([[[[-0.8999, -0.0938,  0.8493],\n",
      "          [-1.1894, -0.0184,  1.0298],\n",
      "          [-0.8632,  0.0759,  1.1224]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.8999, -0.0938,  0.8493],\n",
      "          [-1.1894, -0.0184,  1.0298],\n",
      "          [-0.8632,  0.0759,  1.1224]]]]) \n",
      "\n",
      "### Epoch_79 ###\n",
      "\n",
      "The output is tensor([[[2.9651]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0012174906441941857\n",
      "\n",
      "tensor([[[[-0.8999, -0.0931,  0.8500],\n",
      "          [-1.1894, -0.0177,  1.0305],\n",
      "          [-0.8632,  0.0766,  1.1230]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9869]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00017196385306306183\n",
      "\n",
      "tensor([[[[-0.9002, -0.0933,  0.8500],\n",
      "          [-1.1897, -0.0180,  1.0305],\n",
      "          [-0.8635,  0.0763,  1.1230]]]]) \n",
      "\n",
      "The output is tensor([[[0.0151]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00022802446619607508\n",
      "\n",
      "tensor([[[[-0.9005, -0.0936,  0.8497],\n",
      "          [-1.1900, -0.0183,  1.0302],\n",
      "          [-0.8638,  0.0760,  1.1227]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9005, -0.0936,  0.8497],\n",
      "          [-1.1900, -0.0183,  1.0302],\n",
      "          [-0.8638,  0.0760,  1.1227]]]]) \n",
      "\n",
      "### Epoch_80 ###\n",
      "\n",
      "The output is tensor([[[2.9667]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0011091547785326838\n",
      "\n",
      "tensor([[[[-0.9005, -0.0930,  0.8504],\n",
      "          [-1.1900, -0.0176,  1.0308],\n",
      "          [-0.8638,  0.0767,  1.1234]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9883]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0001375023857690394\n",
      "\n",
      "tensor([[[[-0.9007, -0.0932,  0.8504],\n",
      "          [-1.1902, -0.0179,  1.0308],\n",
      "          [-0.8640,  0.0764,  1.1234]]]]) \n",
      "\n",
      "The output is tensor([[[0.0150]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00022415279818233103\n",
      "\n",
      "tensor([[[[-0.9010, -0.0935,  0.8501],\n",
      "          [-1.1905, -0.0182,  1.0305],\n",
      "          [-0.8643,  0.0761,  1.1231]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9010, -0.0935,  0.8501],\n",
      "          [-1.1905, -0.0182,  1.0305],\n",
      "          [-0.8643,  0.0761,  1.1231]]]]) \n",
      "\n",
      "### Epoch_81 ###\n",
      "\n",
      "The output is tensor([[[2.9682]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0010117425117641687\n",
      "\n",
      "tensor([[[[-0.9010, -0.0929,  0.8507],\n",
      "          [-1.1905, -0.0175,  1.0312],\n",
      "          [-0.8643,  0.0768,  1.1237]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9896]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00010880683112191036\n",
      "\n",
      "tensor([[[[-0.9013, -0.0931,  0.8507],\n",
      "          [-1.1907, -0.0178,  1.0312],\n",
      "          [-0.8645,  0.0766,  1.1237]]]]) \n",
      "\n",
      "The output is tensor([[[0.0148]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00022027887462172657\n",
      "\n",
      "tensor([[[[-0.9015, -0.0934,  0.8504],\n",
      "          [-1.1910, -0.0180,  1.0309],\n",
      "          [-0.8648,  0.0763,  1.1235]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9015, -0.0934,  0.8504],\n",
      "          [-1.1910, -0.0180,  1.0309],\n",
      "          [-0.8648,  0.0763,  1.1235]]]]) \n",
      "\n",
      "### Epoch_82 ###\n",
      "\n",
      "The output is tensor([[[2.9696]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0009240318322554231\n",
      "\n",
      "tensor([[[[-0.9015, -0.0928,  0.8511],\n",
      "          [-1.1910, -0.0174,  1.0315],\n",
      "          [-0.8648,  0.0769,  1.1241]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9908]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 8.505024743499234e-05\n",
      "\n",
      "tensor([[[[-0.9017, -0.0930,  0.8511],\n",
      "          [-1.1912, -0.0176,  1.0315],\n",
      "          [-0.8650,  0.0767,  1.1241]]]]) \n",
      "\n",
      "The output is tensor([[[0.0147]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00021643171203322709\n",
      "\n",
      "tensor([[[[-0.9020, -0.0932,  0.8508],\n",
      "          [-1.1915, -0.0179,  1.0312],\n",
      "          [-0.8653,  0.0764,  1.1238]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9020, -0.0932,  0.8508],\n",
      "          [-1.1915, -0.0179,  1.0312],\n",
      "          [-0.8653,  0.0764,  1.1238]]]]) \n",
      "\n",
      "### Epoch_83 ###\n",
      "\n",
      "The output is tensor([[[2.9709]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0008450036984868348\n",
      "\n",
      "tensor([[[[-0.9020, -0.0927,  0.8513],\n",
      "          [-1.1915, -0.0173,  1.0318],\n",
      "          [-0.8653,  0.0770,  1.1243]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9919]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 6.55178664601408e-05\n",
      "\n",
      "tensor([[[[-0.9022, -0.0928,  0.8513],\n",
      "          [-1.1917, -0.0175,  1.0318],\n",
      "          [-0.8655,  0.0768,  1.1243]]]]) \n",
      "\n",
      "The output is tensor([[[0.0146]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00021259411005303264\n",
      "\n",
      "tensor([[[[-0.9025, -0.0931,  0.8510],\n",
      "          [-1.1920, -0.0178,  1.0315],\n",
      "          [-0.8658,  0.0765,  1.1241]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9025, -0.0931,  0.8510],\n",
      "          [-1.1920, -0.0178,  1.0315],\n",
      "          [-0.8658,  0.0765,  1.1241]]]]) \n",
      "\n",
      "### Epoch_84 ###\n",
      "\n",
      "The output is tensor([[[2.9722]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0007737198029644787\n",
      "\n",
      "tensor([[[[-0.9025, -0.0926,  0.8516],\n",
      "          [-1.1920, -0.0172,  1.0320],\n",
      "          [-0.8658,  0.0771,  1.1246]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9930]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 4.959215220878832e-05\n",
      "\n",
      "tensor([[[[-0.9026, -0.0927,  0.8516],\n",
      "          [-1.1921, -0.0174,  1.0320],\n",
      "          [-0.8659,  0.0769,  1.1246]]]]) \n",
      "\n",
      "The output is tensor([[[0.0144]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00020877360657323152\n",
      "\n",
      "tensor([[[[-0.9029, -0.0930,  0.8513],\n",
      "          [-1.1924, -0.0177,  1.0317],\n",
      "          [-0.8662,  0.0766,  1.1243]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9029, -0.0930,  0.8513],\n",
      "          [-1.1924, -0.0177,  1.0317],\n",
      "          [-0.8662,  0.0766,  1.1243]]]]) \n",
      "\n",
      "### Epoch_85 ###\n",
      "\n",
      "The output is tensor([[[2.9734]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0007093814783729613\n",
      "\n",
      "tensor([[[[-0.9029, -0.0925,  0.8518],\n",
      "          [-1.1924, -0.0171,  1.0323],\n",
      "          [-0.8662,  0.0772,  1.1249]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9939]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 3.673954779515043e-05\n",
      "\n",
      "tensor([[[[-0.9030, -0.0926,  0.8518],\n",
      "          [-1.1925, -0.0173,  1.0323],\n",
      "          [-0.8663,  0.0770,  1.1249]]]]) \n",
      "\n",
      "The output is tensor([[[0.0143]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00020497750665526837\n",
      "\n",
      "tensor([[[[-0.9033, -0.0929,  0.8516],\n",
      "          [-1.1928, -0.0175,  1.0320],\n",
      "          [-0.8666,  0.0768,  1.1246]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9033, -0.0929,  0.8516],\n",
      "          [-1.1928, -0.0175,  1.0320],\n",
      "          [-0.8666,  0.0768,  1.1246]]]]) \n",
      "\n",
      "### Epoch_86 ###\n",
      "\n",
      "The output is tensor([[[2.9745]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0006512626423500478\n",
      "\n",
      "tensor([[[[-0.9033, -0.0924,  0.8521],\n",
      "          [-1.1928, -0.0170,  1.0325],\n",
      "          [-0.8666,  0.0773,  1.1251]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9949]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 2.649631460371893e-05\n",
      "\n",
      "tensor([[[[-0.9034, -0.0925,  0.8521],\n",
      "          [-1.1929, -0.0171,  1.0325],\n",
      "          [-0.8667,  0.0772,  1.1251]]]]) \n",
      "\n",
      "The output is tensor([[[0.0142]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00020120608678553253\n",
      "\n",
      "tensor([[[[-0.9037, -0.0927,  0.8518],\n",
      "          [-1.1932, -0.0174,  1.0322],\n",
      "          [-0.8670,  0.0769,  1.1248]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9037, -0.0927,  0.8518],\n",
      "          [-1.1932, -0.0174,  1.0322],\n",
      "          [-0.8670,  0.0769,  1.1248]]]]) \n",
      "\n",
      "### Epoch_87 ###\n",
      "\n",
      "The output is tensor([[[2.9755]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.000598703685682267\n",
      "\n",
      "tensor([[[[-0.9037, -0.0923,  0.8523],\n",
      "          [-1.1932, -0.0169,  1.0327],\n",
      "          [-0.8670,  0.0774,  1.1253]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9957]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.8452072254149243e-05\n",
      "\n",
      "tensor([[[[-0.9038, -0.0923,  0.8523],\n",
      "          [-1.1933, -0.0170,  1.0327],\n",
      "          [-0.8671,  0.0773,  1.1253]]]]) \n",
      "\n",
      "The output is tensor([[[0.0141]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00019745629106182605\n",
      "\n",
      "tensor([[[[-0.9041, -0.0926,  0.8520],\n",
      "          [-1.1936, -0.0173,  1.0324],\n",
      "          [-0.8674,  0.0770,  1.1250]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9041, -0.0926,  0.8520],\n",
      "          [-1.1936, -0.0173,  1.0324],\n",
      "          [-0.8674,  0.0770,  1.1250]]]]) \n",
      "\n",
      "### Epoch_88 ###\n",
      "\n",
      "The output is tensor([[[2.9765]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0005511395866051316\n",
      "\n",
      "tensor([[[[-0.9041, -0.0922,  0.8525],\n",
      "          [-1.1936, -0.0168,  1.0329],\n",
      "          [-0.8674,  0.0775,  1.1255]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9965]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.2266587873455137e-05\n",
      "\n",
      "tensor([[[[-0.9041, -0.0922,  0.8525],\n",
      "          [-1.1936, -0.0169,  1.0329],\n",
      "          [-0.8674,  0.0774,  1.1255]]]]) \n",
      "\n",
      "The output is tensor([[[0.0139]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00019374840485397726\n",
      "\n",
      "tensor([[[[-0.9044, -0.0925,  0.8522],\n",
      "          [-1.1939, -0.0172,  1.0326],\n",
      "          [-0.8677,  0.0771,  1.1252]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9044, -0.0925,  0.8522],\n",
      "          [-1.1939, -0.0172,  1.0326],\n",
      "          [-0.8677,  0.0771,  1.1252]]]]) \n",
      "\n",
      "### Epoch_89 ###\n",
      "\n",
      "The output is tensor([[[2.9775]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0005080342525616288\n",
      "\n",
      "tensor([[[[-0.9044, -0.0920,  0.8526],\n",
      "          [-1.1939, -0.0167,  1.0331],\n",
      "          [-0.8677,  0.0776,  1.1256]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9972]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 7.638303941348568e-06\n",
      "\n",
      "tensor([[[[-0.9045, -0.0921,  0.8526],\n",
      "          [-1.1940, -0.0168,  1.0331],\n",
      "          [-0.8678,  0.0775,  1.1256]]]]) \n",
      "\n",
      "The output is tensor([[[0.0138]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0001900888019008562\n",
      "\n",
      "tensor([[[[-0.9048, -0.0924,  0.8524],\n",
      "          [-1.1942, -0.0171,  1.0328],\n",
      "          [-0.8680,  0.0772,  1.1254]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9048, -0.0924,  0.8524],\n",
      "          [-1.1942, -0.0171,  1.0328],\n",
      "          [-0.8680,  0.0772,  1.1254]]]]) \n",
      "\n",
      "### Epoch_90 ###\n",
      "\n",
      "The output is tensor([[[2.9783]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0004689425986725837\n",
      "\n",
      "tensor([[[[-0.9048, -0.0919,  0.8528],\n",
      "          [-1.1942, -0.0166,  1.0332],\n",
      "          [-0.8680,  0.0777,  1.1258]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9979]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 4.314355464885011e-06\n",
      "\n",
      "tensor([[[[-0.9048, -0.0920,  0.8528],\n",
      "          [-1.1943, -0.0167,  1.0332],\n",
      "          [-0.8681,  0.0776,  1.1258]]]]) \n",
      "\n",
      "The output is tensor([[[0.0137]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00018645758973434567\n",
      "\n",
      "tensor([[[[-0.9051, -0.0923,  0.8525],\n",
      "          [-1.1946, -0.0169,  1.0330],\n",
      "          [-0.8684,  0.0774,  1.1255]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9051, -0.0923,  0.8525],\n",
      "          [-1.1946, -0.0169,  1.0330],\n",
      "          [-0.8684,  0.0774,  1.1255]]]]) \n",
      "\n",
      "### Epoch_91 ###\n",
      "\n",
      "The output is tensor([[[2.9792]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00043345842277631164\n",
      "\n",
      "tensor([[[[-0.9051, -0.0918,  0.8529],\n",
      "          [-1.1946, -0.0165,  1.0334],\n",
      "          [-0.8684,  0.0778,  1.1259]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9986]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 2.068934918497689e-06\n",
      "\n",
      "tensor([[[[-0.9051, -0.0919,  0.8529],\n",
      "          [-1.1946, -0.0165,  1.0334],\n",
      "          [-0.8684,  0.0778,  1.1259]]]]) \n",
      "\n",
      "The output is tensor([[[0.0135]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00018286783597432077\n",
      "\n",
      "tensor([[[[-0.9054, -0.0921,  0.8527],\n",
      "          [-1.1949, -0.0168,  1.0331],\n",
      "          [-0.8687,  0.0775,  1.1257]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9054, -0.0921,  0.8527],\n",
      "          [-1.1949, -0.0168,  1.0331],\n",
      "          [-0.8687,  0.0775,  1.1257]]]]) \n",
      "\n",
      "### Epoch_92 ###\n",
      "\n",
      "The output is tensor([[[2.9800]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0004012208664789796\n",
      "\n",
      "tensor([[[[-0.9054, -0.0917,  0.8531],\n",
      "          [-1.1949, -0.0164,  1.0335],\n",
      "          [-0.8687,  0.0779,  1.1261]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9992]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 7.13546853603475e-07\n",
      "\n",
      "tensor([[[[-0.9054, -0.0918,  0.8531],\n",
      "          [-1.1949, -0.0164,  1.0335],\n",
      "          [-0.8687,  0.0779,  1.1261]]]]) \n",
      "\n",
      "The output is tensor([[[0.0134]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0001793161645764485\n",
      "\n",
      "tensor([[[[-0.9057, -0.0920,  0.8528],\n",
      "          [-1.1951, -0.0167,  1.0332],\n",
      "          [-0.8689,  0.0776,  1.1258]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9057, -0.0920,  0.8528],\n",
      "          [-1.1951, -0.0167,  1.0332],\n",
      "          [-0.8689,  0.0776,  1.1258]]]]) \n",
      "\n",
      "### Epoch_93 ###\n",
      "\n",
      "The output is tensor([[[2.9807]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0003718914231285453\n",
      "\n",
      "tensor([[[[-0.9057, -0.0916,  0.8532],\n",
      "          [-1.1951, -0.0163,  1.0336],\n",
      "          [-0.8689,  0.0780,  1.1262]]]]) \n",
      "\n",
      "The output is tensor([[[-2.9997]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 8.627830538898706e-08\n",
      "\n",
      "tensor([[[[-0.9057, -0.0916,  0.8532],\n",
      "          [-1.1951, -0.0163,  1.0336],\n",
      "          [-0.8689,  0.0780,  1.1262]]]]) \n",
      "\n",
      "The output is tensor([[[0.0133]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00017580566054675728\n",
      "\n",
      "tensor([[[[-0.9059, -0.0919,  0.8529],\n",
      "          [-1.1954, -0.0166,  1.0334],\n",
      "          [-0.8692,  0.0777,  1.1259]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9059, -0.0919,  0.8529],\n",
      "          [-1.1954, -0.0166,  1.0334],\n",
      "          [-0.8692,  0.0777,  1.1259]]]]) \n",
      "\n",
      "### Epoch_94 ###\n",
      "\n",
      "The output is tensor([[[2.9814]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0003451883385423571\n",
      "\n",
      "tensor([[[[-0.9059, -0.0915,  0.8533],\n",
      "          [-1.1954, -0.0162,  1.0337],\n",
      "          [-0.8692,  0.0781,  1.1263]]]]) \n",
      "\n",
      "The output is tensor([[[-3.0002]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 4.759073135573999e-08\n",
      "\n",
      "tensor([[[[-0.9059, -0.0915,  0.8533],\n",
      "          [-1.1954, -0.0162,  1.0337],\n",
      "          [-0.8692,  0.0781,  1.1263]]]]) \n",
      "\n",
      "The output is tensor([[[0.0131]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00017234862025361508\n",
      "\n",
      "tensor([[[[-0.9062, -0.0918,  0.8530],\n",
      "          [-1.1957, -0.0165,  1.0335],\n",
      "          [-0.8695,  0.0778,  1.1260]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9062, -0.0918,  0.8530],\n",
      "          [-1.1957, -0.0165,  1.0335],\n",
      "          [-0.8695,  0.0778,  1.1260]]]]) \n",
      "\n",
      "### Epoch_95 ###\n",
      "\n",
      "The output is tensor([[[2.9821]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0003208365524187684\n",
      "\n",
      "tensor([[[[-0.9062, -0.0914,  0.8534],\n",
      "          [-1.1957, -0.0161,  1.0338],\n",
      "          [-0.8695,  0.0782,  1.1264]]]]) \n",
      "\n",
      "The output is tensor([[[-3.0007]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 4.797030328518304e-07\n",
      "\n",
      "tensor([[[[-0.9062, -0.0914,  0.8534],\n",
      "          [-1.1957, -0.0161,  1.0338],\n",
      "          [-0.8695,  0.0782,  1.1264]]]]) \n",
      "\n",
      "The output is tensor([[[0.0130]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0001689321215962991\n",
      "\n",
      "tensor([[[[-0.9064, -0.0917,  0.8531],\n",
      "          [-1.1959, -0.0164,  1.0336],\n",
      "          [-0.8697,  0.0779,  1.1261]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9064, -0.0917,  0.8531],\n",
      "          [-1.1959, -0.0164,  1.0336],\n",
      "          [-0.8697,  0.0779,  1.1261]]]]) \n",
      "\n",
      "### Epoch_96 ###\n",
      "\n",
      "The output is tensor([[[2.9827]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00029863486997783184\n",
      "\n",
      "tensor([[[[-0.9064, -0.0913,  0.8535],\n",
      "          [-1.1959, -0.0160,  1.0339],\n",
      "          [-0.8697,  0.0783,  1.1265]]]]) \n",
      "\n",
      "The output is tensor([[[-3.0011]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 1.281449840462301e-06\n",
      "\n",
      "tensor([[[[-0.9064, -0.0913,  0.8535],\n",
      "          [-1.1959, -0.0160,  1.0339],\n",
      "          [-0.8697,  0.0783,  1.1265]]]]) \n",
      "\n",
      "The output is tensor([[[0.0129]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0001655651576584205\n",
      "\n",
      "tensor([[[[-0.9067, -0.0916,  0.8532],\n",
      "          [-1.1962, -0.0163,  1.0336],\n",
      "          [-0.8700,  0.0781,  1.1262]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9067, -0.0916,  0.8532],\n",
      "          [-1.1962, -0.0163,  1.0336],\n",
      "          [-0.8700,  0.0781,  1.1262]]]]) \n",
      "\n",
      "### Epoch_97 ###\n",
      "\n",
      "The output is tensor([[[2.9833]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002783417876344174\n",
      "\n",
      "tensor([[[[-0.9067, -0.0912,  0.8536],\n",
      "          [-1.1962, -0.0159,  1.0340],\n",
      "          [-0.8700,  0.0784,  1.1266]]]]) \n",
      "\n",
      "The output is tensor([[[-3.0015]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 2.369230060139671e-06\n",
      "\n",
      "tensor([[[[-0.9066, -0.0912,  0.8536],\n",
      "          [-1.1961, -0.0159,  1.0340],\n",
      "          [-0.8699,  0.0784,  1.1266]]]]) \n",
      "\n",
      "The output is tensor([[[0.0127]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00016224422142840922\n",
      "\n",
      "tensor([[[[-0.9069, -0.0915,  0.8533],\n",
      "          [-1.1964, -0.0161,  1.0337],\n",
      "          [-0.8702,  0.0782,  1.1263]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9069, -0.0915,  0.8533],\n",
      "          [-1.1964, -0.0161,  1.0337],\n",
      "          [-0.8702,  0.0782,  1.1263]]]]) \n",
      "\n",
      "### Epoch_98 ###\n",
      "\n",
      "The output is tensor([[[2.9839]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002597761631477624\n",
      "\n",
      "tensor([[[[-0.9069, -0.0911,  0.8536],\n",
      "          [-1.1964, -0.0158,  1.0340],\n",
      "          [-0.8702,  0.0785,  1.1266]]]]) \n",
      "\n",
      "The output is tensor([[[-3.0019]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 3.6726216876559192e-06\n",
      "\n",
      "tensor([[[[-0.9068, -0.0911,  0.8536],\n",
      "          [-1.1963, -0.0158,  1.0340],\n",
      "          [-0.8701,  0.0785,  1.1266]]]]) \n",
      "\n",
      "The output is tensor([[[0.0126]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00015898700803518295\n",
      "\n",
      "tensor([[[[-0.9071, -0.0914,  0.8534],\n",
      "          [-1.1966, -0.0160,  1.0338],\n",
      "          [-0.8704,  0.0783,  1.1264]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9071, -0.0914,  0.8534],\n",
      "          [-1.1966, -0.0160,  1.0338],\n",
      "          [-0.8704,  0.0783,  1.1264]]]]) \n",
      "\n",
      "### Epoch_99 ###\n",
      "\n",
      "The output is tensor([[[2.9844]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00024278649652842432\n",
      "\n",
      "tensor([[[[-0.9071, -0.0910,  0.8537],\n",
      "          [-1.1966, -0.0157,  1.0341],\n",
      "          [-0.8704,  0.0786,  1.1267]]]]) \n",
      "\n",
      "The output is tensor([[[-3.0023]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 5.127958502271213e-06\n",
      "\n",
      "tensor([[[[-0.9071, -0.0910,  0.8537],\n",
      "          [-1.1965, -0.0157,  1.0341],\n",
      "          [-0.8703,  0.0786,  1.1267]]]]) \n",
      "\n",
      "The output is tensor([[[0.0125]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.00015577471640426666\n",
      "\n",
      "tensor([[[[-0.9073, -0.0913,  0.8534],\n",
      "          [-1.1968, -0.0159,  1.0339],\n",
      "          [-0.8706,  0.0784,  1.1264]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9073, -0.0913,  0.8534],\n",
      "          [-1.1968, -0.0159,  1.0339],\n",
      "          [-0.8706,  0.0784,  1.1264]]]]) \n",
      "\n",
      "### Epoch_100 ###\n",
      "\n",
      "The output is tensor([[[2.9849]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0002272187266498804\n",
      "\n",
      "tensor([[[[-0.9073, -0.0910,  0.8537],\n",
      "          [-1.1968, -0.0156,  1.0342],\n",
      "          [-0.8706,  0.0787,  1.1267]]]]) \n",
      "\n",
      "The output is tensor([[[-3.0026]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 6.68681605020538e-06\n",
      "\n",
      "tensor([[[[-0.9073, -0.0909,  0.8537],\n",
      "          [-1.1967, -0.0156,  1.0342],\n",
      "          [-0.8705,  0.0787,  1.1267]]]]) \n",
      "\n",
      "The output is tensor([[[0.0124]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0001526128762634471\n",
      "\n",
      "tensor([[[[-0.9075, -0.0911,  0.8535],\n",
      "          [-1.1970, -0.0158,  1.0339],\n",
      "          [-0.8708,  0.0785,  1.1265]]]]) \n",
      "\n",
      "The output is tensor([[[0.]]], grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Loss is 0.0\n",
      "\n",
      "tensor([[[[-0.9075, -0.0911,  0.8535],\n",
      "          [-1.1970, -0.0158,  1.0339],\n",
      "          [-0.8708,  0.0785,  1.1265]]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torchsummary\n",
    "import torch.optim as optim\n",
    "\n",
    "class OneLayerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneLayerModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "# only one image\n",
    "# imgs = torch.tensor([[[[0, 1, 1] for _ in range(3)]], dtype=torch.float32) # [1, 1, 3, 3] = [batch, channel, h, w]\n",
    "# labels = torch.tensor([[[[3]]], dtype=torch.float32)\n",
    "\n",
    "# two images\n",
    "# imgs = torch.tensor([[[[0, 1, 1] for _ in range(3)]], [[[1, 1, 0] for _ in range(3)]]], dtype=torch.float32) # [1, 1, 3, 3] = [batch, channel, h, w]\n",
    "# labels = torch.tensor([[[[3]]], [[[-3]]]], dtype=torch.float32)\n",
    "\n",
    "'''\n",
    "tensor([[[[-1.1521, -0.0302,  0.8420],\n",
    "          [-0.9476,  0.1549,  1.0120],\n",
    "          [-0.9611, -0.0593,  1.0756]]]])\n",
    "          \n",
    "tensor([[[[-0.7730,  0.0423,  0.8390],\n",
    "          [-1.0702,  0.3320,  1.1915],\n",
    "          [-1.3074, -0.2187,  0.8084]]]]) \n",
    "'''\n",
    "\n",
    "# three images\n",
    "# imgs = torch.tensor([[[[0, 1, 1] for _ in range(3)]], [[[1, 1, 0] for _ in range(3)]], [[[1, 1, 1] for _ in range(3)]]], dtype=torch.float32) # [1, 1, 3, 3] = [batch, channel, h, w]\n",
    "# labels = torch.tensor([[[[3]]], [[[-3]]], [[[0]]]], dtype=torch.float32)\n",
    "\n",
    "'''\n",
    "tensor([[[[-0.9245,  0.1166,  0.9693],\n",
    "          [-1.0933, -0.1440,  1.1173],\n",
    "          [-1.0377,  0.1175,  0.8462]]]])\n",
    "'''\n",
    "\n",
    "# four images\n",
    "imgs = torch.tensor([[[[0, 1, 1] for _ in range(3)]], [[[1, 1, 0] for _ in range(3)]], [[[1, 1, 1] for _ in range(3)]], [[[0, 0, 0] for _ in range(3)]]], dtype=torch.float32) # [1, 1, 3, 3] = [batch, channel, h, w]\n",
    "labels = torch.tensor([[[[3]]], [[[-3]]], [[[0]]], [[[0]]]], dtype=torch.float32)\n",
    "\n",
    "'''\n",
    "tensor([[[[-0.9075, -0.0911,  0.8535],\n",
    "          [-1.1970, -0.0158,  1.0339],\n",
    "          [-0.8708,  0.0785,  1.1265]]]]) \n",
    "'''\n",
    "\n",
    "model = OneLayerModel()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "def print_param():\n",
    "    global model\n",
    "    for param in model.parameters():\n",
    "        print(param.data, '\\n')\n",
    "        \n",
    "print_param()\n",
    "\n",
    "for epoch in range(1, num_epoch+1):\n",
    "    print(f'### Epoch_{epoch} ###\\n')\n",
    "    \n",
    "    for img, label in zip(imgs, labels):\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(img)\n",
    "        \n",
    "        print(f'The output is {outputs}\\n')\n",
    "        \n",
    "        loss = criterion(outputs, label)\n",
    "        \n",
    "        print(f'Loss is {loss}\\n')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        print_param()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TwoLayerModel - 3x3 kernel - 5x5 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n",
      "\n",
      "tensor([[[[ 0.0278,  0.2676, -0.0180],\n",
      "          [ 0.2433, -0.1290,  0.0382],\n",
      "          [ 0.0668,  0.2975,  0.0502]]]], device='cuda:0') \n",
      "\n",
      "tensor([[-0.0600, -0.1601,  0.0104, -0.1591,  0.0815,  0.2578,  0.3255,  0.1186,\n",
      "         -0.2159]], device='cuda:0') \n",
      "\n",
      "### Epoch_1 ###\n",
      "\n",
      "Epoch loss is 1.091\n",
      "\n",
      "Outputs: [0.52, 0.5, 0.5, 0.5, 0.59, 0.57, 0.63, 0.61, 0.61, 0.57]\n",
      "Labels: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "### Epoch_2 ###\n",
      "\n",
      "Epoch loss is 0.896\n",
      "\n",
      "Outputs: [1.0, 0.5, 0.5, 0.5, 0.99, 0.5, 0.99, 0.5, 1.0, 0.5]\n",
      "Labels: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "### Epoch_3 ###\n",
      "\n",
      "Epoch loss is 0.895\n",
      "\n",
      "Outputs: [1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5]\n",
      "Labels: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "### Epoch_4 ###\n",
      "\n",
      "Epoch loss is 0.894\n",
      "\n",
      "Outputs: [1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5]\n",
      "Labels: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "### Epoch_5 ###\n",
      "\n",
      "Epoch loss is 0.894\n",
      "\n",
      "Outputs: [1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5]\n",
      "Labels: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "### Epoch_6 ###\n",
      "\n",
      "Epoch loss is 0.894\n",
      "\n",
      "Outputs: [1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5]\n",
      "Labels: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "### Epoch_7 ###\n",
      "\n",
      "Epoch loss is 0.894\n",
      "\n",
      "Outputs: [1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5]\n",
      "Labels: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "### Epoch_8 ###\n",
      "\n",
      "Epoch loss is 0.894\n",
      "\n",
      "Outputs: [1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5]\n",
      "Labels: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "### Epoch_9 ###\n",
      "\n",
      "Epoch loss is 0.894\n",
      "\n",
      "Outputs: [1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5]\n",
      "Labels: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "### Epoch_10 ###\n",
      "\n",
      "Epoch loss is 0.894\n",
      "\n",
      "Outputs: [1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5]\n",
      "Labels: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "### Epoch_11 ###\n",
      "\n",
      "Epoch loss is 0.894\n",
      "\n",
      "Outputs: [1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5]\n",
      "Labels: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "### Epoch_12 ###\n",
      "\n",
      "Epoch loss is 0.894\n",
      "\n",
      "Outputs: [1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5]\n",
      "Labels: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "### Epoch_13 ###\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 123\u001b[0m\n\u001b[1;32m    119\u001b[0m output \u001b[38;5;241m=\u001b[39m model(img)\n\u001b[1;32m    121\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, label)\n\u001b[0;32m--> 123\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    127\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:261\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    259\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdetach_()\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m foreach \u001b[38;5;129;01mor\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mis_sparse):\n\u001b[1;32m    263\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mzero_()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# import torchsummary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device is {device}\\n')\n",
    "\n",
    "class TwoLayerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayerModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "        self.fc1 = nn.Linear(9, 1, bias=False)\n",
    "        # self.fc1 = nn.Linear(9, 2, bias=False)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        # x = self.softmax(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# random 100 images\n",
    "imgs = []\n",
    "labels = []\n",
    "label_list = []\n",
    "\n",
    "n = 512\n",
    "i, j = 0, 0\n",
    "while i < n or j < n:\n",
    "    row = torch.randint(0, 2, (5,))\n",
    "    if torch.all(row == 0) or torch.all(row == 1):\n",
    "        if i < n:\n",
    "            label = torch.tensor([[0]], dtype=torch.float32)\n",
    "            # label = torch.tensor([0], dtype=torch.float32)\n",
    "            label_ = 0\n",
    "            i += 1\n",
    "            # print('line x', row)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        consecutive = False\n",
    "        for k in range(4):\n",
    "            if row[k] == row[k+1]:\n",
    "                consecutive = True\n",
    "                break\n",
    "        if consecutive:\n",
    "            if j < n:\n",
    "                label = torch.tensor([[1]], dtype=torch.float32)\n",
    "                # label = torch.tensor([1], dtype=torch.float32)\n",
    "                label_ = 1\n",
    "                j += 1\n",
    "                # print('line o', row)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            if i < n:\n",
    "                label = torch.tensor([[0]], dtype=torch.float32)\n",
    "                # label = torch.tensor([0], dtype=torch.float32)\n",
    "                label_ = 0\n",
    "                i += 1\n",
    "                # print('line x', row)\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "    img = row.repeat(5, 1).unsqueeze(0) # (1,5,5)\n",
    "    imgs.append(img)\n",
    "    labels.append(label)\n",
    "    label_list.append(label_)\n",
    "\n",
    "model = TwoLayerModel()\n",
    "\n",
    "model.to(device)\n",
    "imgs = torch.stack(imgs).to(device)\n",
    "labels = torch.stack(labels).to(device)\n",
    "\n",
    "indices = np.arange(2*n)\n",
    "np.random.shuffle(indices)\n",
    "imgs, labels = imgs[indices], labels[indices]\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epoch = 32\n",
    "\n",
    "def print_param():\n",
    "    global model\n",
    "    for param in model.parameters():\n",
    "        print(param.data, '\\n')\n",
    "        \n",
    "print_param()\n",
    "\n",
    "for epoch in range(1, num_epoch+1):\n",
    "    print(f'### Epoch_{epoch} ###\\n')\n",
    "    \n",
    "    loss_sum = 0\n",
    "    output_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for img, label in zip(imgs, labels):\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(img)\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # print(f'The output is {output}\\n')\n",
    "        \n",
    "        # print(f'Loss is {loss}\\n')\n",
    "        \n",
    "        # print_param()\n",
    "        \n",
    "        loss_sum += loss\n",
    "        output_list.append(round(output.item(), 2))\n",
    "        label_list.append(label.item())\n",
    "    \n",
    "    loss_sum = round(loss_sum.item() / n, 3)\n",
    "        \n",
    "    print(f'Epoch loss is {loss_sum}\\n')\n",
    "    print(f'Outputs: {output_list[0:10]}')\n",
    "    print(f'Labels:  {label_list[0:10]}\\n')\n",
    "\n",
    "print_param()\n",
    "\n",
    "p_list = []\n",
    "r_list = []\n",
    "f1_list = []\n",
    "\n",
    "threshold_list = [i / 100 for i in range(101)] # 0, 0.01, ..., 1.00\n",
    "for threshold in threshold_list:\n",
    "\n",
    "    output_th= [1.0 if x > threshold else 0.0 for x in output_list]\n",
    "\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for o, l in zip(output_th, label_list):\n",
    "        if o == l:\n",
    "            if o == 1.0:\n",
    "                tp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        else:\n",
    "            if o == 1.0:\n",
    "                fp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    precision = tp / (tp+fp+0.001)\n",
    "    recall = tp / (tp+fn+0.001)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall+ 0.001)\n",
    "    \n",
    "    p_list.append(precision)\n",
    "    r_list.append(recall)\n",
    "    f1_list.append(f1_score)\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame({'T': threshold_list, 'P': p_list, 'R': r_list, 'F1': f1_list})\n",
    "\n",
    "fig = px.line(df, x='T', y=['P', 'R', 'F1'], title='Precision, Recall & F1 score')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
